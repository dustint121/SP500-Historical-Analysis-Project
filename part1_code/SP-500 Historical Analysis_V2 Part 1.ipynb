{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"####  Imports and Credentials"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 1,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"Welcome to the Glue Interactive Sessions Kernel\n",
						"For more information on available magic commands, please type %help in any new cell.\n",
						"\n",
						"Please view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\n",
						"Installed kernel version: 1.0.7 \n",
						"There is no current session.\n",
						"Additional python modules to be included:\n",
						"pandas_market_calendars==4.4.1\n",
						"opencv-python==4.10.0.84\n",
						"bs4==0.0.2\n",
						"Current idle_timeout is None minutes.\n",
						"idle_timeout has been set to 15 minutes.\n",
						"Setting Glue version to: 4.0\n",
						"Previous worker type: None\n",
						"Setting new worker type to: G.1X\n",
						"Previous number of workers: None\n",
						"Setting new number of workers to: 10\n",
						"Trying to create a Glue session for the kernel.\n",
						"Session Type: glueetl\n",
						"Worker Type: G.1X\n",
						"Number of Workers: 10\n",
						"Idle Timeout: 15\n",
						"Session ID: 1f282af4-1511-46e0-a187-105513991d1b\n",
						"Applying the following default arguments:\n",
						"--glue_kernel_version 1.0.7\n",
						"--enable-glue-datacatalog true\n",
						"--additional-python-modules pandas_market_calendars==4.4.1,opencv-python==4.10.0.84,bs4==0.0.2\n",
						"Waiting for session 1f282af4-1511-46e0-a187-105513991d1b to get into ready status...\n",
						"Session 1f282af4-1511-46e0-a187-105513991d1b has been created.\n",
						"Start session\n"
					]
				}
			],
			"source": [
				"%stop_session\n",
				"\n",
				"%additional_python_modules pandas_market_calendars==4.4.1, opencv-python==4.10.0.84, bs4==0.0.2\n",
				"\n",
				"%idle_timeout 15\n",
				"%glue_version 4.0\n",
				"%worker_type G.1X\n",
				"%number_of_workers 10\n",
				"\n",
				"print('Start session')"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"import pandas as pd\n",
				"import numpy as np\n",
				"import requests\n",
				"import json\n",
				"from datetime import datetime\n",
				"import re\n",
				"import boto3\n",
				"import pandas_market_calendars as mcal\n",
				"import cv2 \n",
				"from bs4 import BeautifulSoup\n",
				"from io import StringIO"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 3,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"import sys\n",
				"from awsglue.transforms import *\n",
				"from awsglue.utils import getResolvedOptions\n",
				"from pyspark.context import SparkContext\n",
				"from awsglue.context import GlueContext\n",
				"from awsglue.job import Job\n",
				"  \n",
				"sc = SparkContext.getOrCreate()\n",
				"glueContext = GlueContext(sc)\n",
				"spark = glueContext.spark_session\n",
				"job = Job(glueContext)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"from awsglue.utils import getResolvedOptions\n",
				"arguments = getResolvedOptions(sys.argv, ['apikey', 'tiingo_token', 'username', 'password'])\n",
				"apikey, tiingo_token, username, password = arguments['apikey'], arguments['tiingo_token'], arguments['username'], arguments['password']"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Company Profile Functions"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 5,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"def get_tiingo_company_regular_data(ticker, company_name, company_profile):     \n",
				"    if company_name == None: return None\n",
				"\n",
				"    headers = {'Content-Type': 'application/json'}\n",
				"    tiingo_URL = \"https://api.tiingo.com/tiingo/daily/\" + ticker + \"?token=\" + tiingo_token\n",
				"    tiingo_data= requests.get(tiingo_URL, headers=headers).json()\n",
				"    if tiingo_data != {'detail': 'Not found.'}:\n",
				"        is_valid_exchange = tiingo_data[\"exchangeCode\"] in [\"NASDAQ\", \"NYSE\"]\n",
				"        description = (tiingo_data[\"description\"].replace(',', '').replace('. ', ' ').replace('.', ' ').lower() \n",
				"                        if tiingo_data[\"description\"] != None else \"\")\n",
				"\n",
				"        if is_valid_exchange == False and ticker in [\"SBNY\"]:   #later delisted from NYSE or NASDAQ\n",
				"            is_valid_exchange = True\n",
				"            \n",
				"        company_name = (company_name.lower().replace(',', '').replace('. ', ' ').replace('.', ' ').replace(\"'\",'`')\n",
				"                        .replace('(',\"\").replace(')',\"\").strip())\n",
				"        \n",
				"        is_right_company = False\n",
				"        if tiingo_data[\"name\"] != None:\n",
				"            is_right_company = all([val in [\"inc\",\"co\",\"corp\",\"corporation\",\"company\",\"companies\",\"the\",\"-\",\"&\",\n",
				"                                            \"int`l\",\"plc\",\"ltd\",\"llc\",'(the)'] \n",
				"                                    or val in tiingo_data[\"name\"].lower() or val in description.split()[:20]\n",
				"                                    for val in company_name.split()])\n",
				"\n",
				"        ticker_exception_list = [\"DPZ\",\"CPAY\",\"CBOE\",\"CB\",\"ORLY\",\"DOC\",\"BXP\",\"EL\",\"LH\",\"BF-B\",\"GE\",\"NSC\",\"SLB\"]\n",
				"        #500s\n",
				"        ticker_exception_list += [\"XOM\",\"FRCB\",\"SIVBQ\",\"DISCK\",\"MRKT\",\"DINO\",\"AGN\"]\n",
				"        #600s\n",
				"        ticker_exception_list += [\"GGP\",\"LVLT\",\"DD\",\"BBBYQ\",\"MNKKQ\",\"FTR\",\"ENDPQ\",\"TE\",\"VAL\",\"CNX\",\"ALTR1\"\n",
				"                                  ,\"CMCSA\",\"PLL1\",\"DTV1\"]\n",
				"        #700s\n",
				"        ticker_exception_list += [\"LIFE2\",\"DELL1\",\"FHN\",\"DFODQ\",\"BIGGQ\",\"RRD\",\"SUN1\",\"ATGE\",\"SHLDQ\",\"MMI1\",\"SUNEQ\",\"NSM1\"\n",
				"                                  ,\"Q1\",\"PTV\",\"MIL1\",\"XTO\",\"BDK\",\"SGP\",\"WINMQ\"]\n",
				"        #800s\n",
				"        ticker_exception_list += [\"WYE\",\"CTX1\",\"EQ1\",\"ROH\",\"SOV\",\"UST1\",\"AW\",\"ABI1\",\"BUD1\",\"ASH\",\"WWY\",\"WEN\",\"SAF2\",\"FNMA\",\"FMCC\"\n",
				"                                  ,\"IAC\",\"OMX1\",\"CCTYQ\",\"CBH1\",\"CZR\",\"DJ\",\"AT1\",\"BOL\",\"AV1\",\"TXU\",\"ASN\",\"SLR\",\"CBSS\",\"KSE\"\n",
				"                                  ,\"BMET\",\"MEL\",\"PD1\",\"PGL\",\"APCC\",\"EOP\",\"SBL\",\"BLS\",\"NFB\"]\n",
				"        #900s\n",
				"        ticker_exception_list += [\"FSH\",\"GTW\",\"CTB\",\"EC1\",\"ABS\",\"CHIR1\",\"CIN\",\"MYG\",\"BR1\",\"RBK\",\"KRB\",\"DPHIQ\",\"G1\",\"MAY\"\n",
				"                                  ,\"NXTL\",\"TOY\",\"GLK\",\"VRTS1\",\"S1\",\"WLP1\",\"SOTR\",\"AWE\",\"ONE1\",\"AM1\",\"FBF\",\"CE1\",\"BIIB\",\"QTRN\"\n",
				"                                  ,\"PHA\",\"EHC\",\"RATL\",\"INCLF\",\"AL1\",\"SHEL\",\"PDG\",\"IMNX\",\"CNXT1\",\"WLL1\",\"MEA1\",\"KM\",\"HM\"\n",
				"                                  ,\"RAL\",\"ENRNQ\",\"GPU\",\"TX1\"]\n",
				"        #1000s\n",
				"        ticker_exception_list += [\"TOS\",\"WB2\",\"AGC1\",\"ETS\",\"CEN1\",\"OK\",\"SUB1\",\"UK1\",\"CGP\",\"SMI1\",\"PRD\",\"VO1\",\"FJ\",\"ACKH\"\n",
				"                                  ,\"PWJ\",\"CG1\",\"EFU1\",\"UCM\",\"MKG\",\"YNR\",\"NCE\",\"RADCQ\",\"GTE1\",\"MZIAQ\",\"WLA\",\"CHA1\",\"USW\",\n",
				"                                  \"CSR1\",\"TMC-A\",\"SMS\",\"MIR1\",\"JOS\",\"CBS1\",\"ARC1\",\"PNU\",\"PBY1\",\"FLTWQ\",\"CNG\",\"RNB\",\"PPW\",\n",
				"                                  \"CSE1\",\"CYM\",\"DGN\",\"AIT1\",\"PHB1\",\"MBWM\",\"RYC\",\"NLC1\",\"BFI\",\"TA2\",\"PVT1\"]\n",
				"        #1100s\n",
				"        ticker_exception_list += [\"ATI1\",\"ASND1\",\"MWI\",\"FMY1\",\"AMP1\",\"TCOMA\",\"HBOC\",\"SAI\",\"PZE1\",\"CCI1\",\"GSX1\",\"USS\",\"FCN1\"\n",
				"                                  ,\"AHM1\",\"DI1\",\"MNR1\",\"BAY1\",\"DIGI2\",\"WMX\",\"SK1\",\"JH\",\"BEV\",\"SFS1\",\"INGR1\"]\n",
				"\n",
				"        if ticker in ticker_exception_list or (is_valid_exchange and is_right_company):\n",
				"            company_profile[\"company_name\"] = tiingo_data[\"name\"].title()\n",
				"            company_profile[\"is_delisted\"] = \"delisted\" in tiingo_data[\"description\"][:15].lower()\n",
				"            company_profile[\"description\"] = tiingo_data[\"description\"].replace(\"DELISTED - \", '')\n",
				"            company_profile[\"exchange\"] = tiingo_data[\"exchangeCode\"] if tiingo_data[\"exchangeCode\"] in [\"NYSE\", \"NASDAQ\"] else None\n",
				"            if company_profile[\"description\"] == tiingo_data[\"name\"]:\n",
				"                company_profile[\"description\"] = None\n",
				"            return True\n",
				"        else:\n",
				"            if ticker not in [\"BK\",\"BF-B\",\"LLY\",\"GE\",\"IBM\"]:\n",
				"                print(\"Invalid Tiingo data for ticker symbol: \" + ticker)\n",
				"                return False\n",
				"    else:\n",
				"        print(\"No Tiingo data retrieved for: \" + ticker)\n",
				"        return False\n",
				"\n",
				"    #DPS company data is not found on meta for tiingo or on FMP\n",
				"\n",
				"\n",
				"def get_tiingo_company_metadata(ticker, company_profile, meta_data_list):\n",
				"    tiingo_meta_data_index = {'A': 0, 'B': 1787, 'C': 2763, 'D': 4607, 'E': 5244, 'F': 6052, 'G': 6866, \n",
				"                            'H': 7687, 'I': 8349, 'J': 9170, 'K': 9383, 'L': 9730, 'M': 10382, 'N': 11485, \n",
				"                            'O': 12269, 'P': 12752, 'Q': 13899, 'R': 14030, 'S': 14729, 'T': 16316, 'U': 17321, \n",
				"                            'V': 17665, 'W': 18158, 'X': 18638, 'Y': 18773, 'Z': 18851}\n",
				"    \n",
				"    #weird edge cases\n",
				"    if ticker == \"MDR\":\n",
				"        company_profile[\"sector\"] = \"Energy\"\n",
				"        company_profile[\"industry\"] = \"Oil & Gas Equipment & Services\"\n",
				"        company_profile[\"source\"] = \"tiingo\"\n",
				"        return True\n",
				"    if ticker == \"MYG\": ticker = \"MYG1\"\n",
				"    if ticker == \"MII\": ticker = \"MII1\"\n",
				"\n",
				"\n",
				"    first_letter = ticker[0]\n",
				"    starting_index = tiingo_meta_data_index[first_letter]\n",
				"    stopping_index = None\n",
				"    if first_letter == 'Z':\n",
				"        stopping_index = -1\n",
				"    else:\n",
				"        next_letter = list(tiingo_meta_data_index.keys())[list(tiingo_meta_data_index.keys()).index(first_letter) + 1]\n",
				"        stopping_index = tiingo_meta_data_index[next_letter]\n",
				"    meta_data_list = meta_data_list[starting_index:stopping_index]\n",
				"    match_found = False\n",
				"    for i, meta_data in enumerate(meta_data_list):\n",
				"        if ticker.lower() == meta_data[\"ticker\"]:\n",
				"            company_profile[\"sector\"] = meta_data[\"sector\"]\n",
				"            company_profile[\"industry\"] = meta_data[\"industry\"]\n",
				"            company_profile[\"source\"] = \"tiingo\"\n",
				"            match_found = True\n",
				"            return True\n",
				"    if match_found == False:\n",
				"        print(\"No tiingo meta data found for: \" + ticker)\n",
				"        return False\n",
				"\n",
				"\n",
				"def get_fmp_metadata(ticker, company_name, company_profile, index):\n",
				"    # fmp_bio_list = fmpsdk.company_profile(apikey=apikey, symbol=ticker)\n",
				"    request = requests.get(\"https://financialmodelingprep.com/api/v3/profile/\" + ticker + \"?apikey=\" + apikey)\n",
				"    fmp_bio_list = request.json()\n",
				"    if (len(fmp_bio_list) > 0):\n",
				"        fmp_data = fmp_bio_list[0]\n",
				"        is_valid_exchange = fmp_data[\"exchangeShortName\"] in [\"NASDAQ\", \"NYSE\"]\n",
				"        company_name = company_name.replace('. ', ' ').replace('.', ' ') #do not remove commas, just \".\"\n",
				"        is_right_company = False\n",
				"        if fmp_data[\"companyName\"] != None:\n",
				"            is_right_company = all([val in [\"inc\",\"co\",\"corp\",\"corporation\",\"company\",\"companies\",\"the\",\"-\",\"&\",\n",
				"                                            \"int`l\",\"plc\",\"ltd\",\"llc\",'(the)'] \n",
				"                                    or val in fmp_data[\"companyName\"].lower()\n",
				"                                    for val in company_name.lower().split()])\n",
				"            if is_right_company == False: \n",
				"                is_right_company = company_name.lower()[:8] in fmp_data[\"companyName\"].lower().replace('. ', ' ').replace('.', ' ')\n",
				"\n",
				"        has_exception = False\n",
				"        if has_exception == False: has_exception = index<500 and ticker in [\"BK\",\"BF-B\",\"LLY\",\"GE\",\"IMB\"] #<500; unneeded\n",
				"        if has_exception == False: has_exception = 500<=index<600 and ticker in [\"XOM\"] #500s; unneeded\n",
				"        #nothing in 600s\n",
				"        if has_exception == False: has_exception = 800<=index<900 and ticker in [\"FNMA\", \"FMCC\", \"IAC\"] #800s\n",
				"        if has_exception == False: has_exception = 900<=index<1000 and ticker in [\"SHEL\"] #900s\n",
				"        #nothing in 1000s, 1100s\n",
				"        if has_exception or (is_valid_exchange and is_right_company):\n",
				"            company_profile[\"company_name\"] = fmp_data[\"companyName\"]\n",
				"            company_profile[\"sector\"] = fmp_data[\"sector\"]\n",
				"            company_profile[\"industry\"] = fmp_data[\"industry\"]\n",
				"            company_profile[\"is_delisted\"] = not fmp_data[\"isActivelyTrading\"]\n",
				"            company_profile[\"description\"] = fmp_data[\"description\"]\n",
				"            company_profile[\"source\"] = \"fmp\"\n",
				"            company_profile[\"exchange\"] = fmp_data[\"exchangeShortName\"] if fmp_data[\"exchangeShortName\"] in [\"NASDAQ\", \"NYSE\"] else None\n",
				"\n",
				"\n",
				"            if fmp_data[\"sector\"] in [None, \"\"]:\n",
				"                print(\"Issue with fmp metadata: \" + ticker)\n",
				"                return False\n",
				"            return True\n",
				"        else: \n",
				"            print(\"Invalid FMP data for ticker symbol: \" + ticker)\n",
				"            return False\n",
				"\n",
				"    else:        \n",
				"        print(\"No FMP data retrieved for: \" + ticker)\n",
				"        return False\n",
				"\n",
				"#will return the company profile metadata for edge cases or return None\n",
				"def get_company_metadata_for_edge_cases(ticker, index):\n",
				"    company_profiles = {\n",
				"        (\"INFO\", 545): {\n",
				"            \"company_name\": \"IHS Markit Ltd\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Information Technology Services\",\"exchange\": \"NYSE\"},\n",
				"        (\"STI\", 586): {\n",
				"            \"company_name\": \"SunTrust Banks Inc\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Banks - Regional\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"LLL\", 595): {\n",
				"            \"company_name\": \"L3 Communications Holdings Inc\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Industrials\",\"industry\": \"Aerospace & Defense\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"CA\", 611): {\n",
				"            \"company_name\": \"CA Inc\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Software - Infrastructure\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"XL\", 612): {\n",
				"            \"company_name\": \"XL Group Ltd\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Insurance - Property & Casualty\",\"exchange\": \"NYSE\"},\n",
				"        (\"DPS\", 614): {\n",
				"            \"company_name\": \"Dr Pepper Snapple Group Inc\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Consumer Defensive\",\"industry\": \"Beverages - Non-Alcoholic\",\"exchange\": \"NYSE\"},\n",
				"        (\"WYND\", 620): {\n",
				"            \"company_name\": \"Wyndham Worldwide Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Consumer Cyclical\",\"industry\": \"Lodging\",\"exchange\": \"NYSE\"},\n",
				"        (\"DOW\", 629): {\n",
				"            \"company_name\": \"Dow Chemical Company\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Basic Materials\",\"industry\": \"Chemicals\",\"exchange\": \"NYSE\"},\n",
				"        (\"HAR\", 648): {\n",
				"            \"company_name\": \"Harman International Industries IncDE\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Consumer Electronics\",\"exchange\": \"NYSE\"},\n",
				"        (\"SE\", 652): {\n",
				"            \"company_name\": \"Spectra Energy Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Utilities\",\"industry\": \"Utilities - Regulated Gas\",\"exchange\": \"NYSE\"},\n",
				"        (\"EMC\", 659): {\n",
				"            \"company_name\": \"EMC Corporation\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Hardware, Equipment & Parts\",\"exchange\": \"NYSE\"},\n",
				"        (\"FRX\", 714): {\n",
				"            \"company_name\": \"Forest Laboratories Inc\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Healthcare\",\"industry\": \"Biotechnology\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"LSI\", 716): {\n",
				"            \"company_name\": \"LSI Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Semiconductors\",\"source\": \"tiingo\",\"exchange\": \"NASDAQ\"},\n",
				"        (\"BEAM\", 718): {\n",
				"            \"company_name\": \"Beam Suntory Inc\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Consumer Defensive\",\"industry\": \"Beverages - Wineries & Distilleries\",\"exchange\": \"NYSE\"},\n",
				"        (\"JCP\", 726): {\n",
				"            \"company_name\": \"JCPenney\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Consumer Cyclical\",\"industry\": \"Department Stores\",\"exchange\": \"NYSE\"},\n",
				"        (\"NYX\", 727): {\n",
				"            \"company_name\": \"NYSE Euronext\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Asset Management\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"S\", 732): {\n",
				"            \"company_name\": \"Sprint Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Communication Services\",\"industry\": \"Telecom Services\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"PGN\", 750): {\n",
				"            \"company_name\": \"Progress Energy Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Utilities\",\"industry\": \"Utilities - Regulated Electric\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"NVLS\", 752): {\n",
				"            \"company_name\": \"Novellus Systems Inc\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Semiconductor Equipment & Materials\",\"source\": \"tiingo\",\"exchange\": \"NASDAQ\"},\n",
				"        (\"EP\", 753): {\n",
				"            \"company_name\": \"El Paso Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Energy\",\"industry\": \"Oil & Gas E&P\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"CEG\", 757): {\n",
				"            \"company_name\": \"Constellation Energy Group Inc\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Utilities\",\"industry\": \"Utilities - Regulated Electric\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"CPWR\", 758): {\n",
				"            \"company_name\": \"Compuware Corporation\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Software - Services\",\"exchange\": \"NASDAQ\"},\n",
				"        (\"MI\", 767): {\n",
				"            \"company_name\": \"Marshall & Ilsley Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Banks - Regional\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"SII\", 782): {\n",
				"            \"company_name\": \"Smith International\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Energy\",\"industry\": \"Oil & Gas Equipment & Services\",\"exchange\": \"NYSE\"},\n",
				"        (\"STR\", 784): {\n",
				"            \"company_name\": \"Questar Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Energy\",\"industry\": \"Oil & Gas E&P\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"JAVA\", 792): {\n",
				"            \"company_name\": \"Sun Microsystems Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Scientific & Technical Instruments\",\"source\": \"tiingo\",\"exchange\": \"NASDAQ\"},\n",
				"        (\"DYN\", 797): {\n",
				"            \"company_name\": \"Dynegy Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Utilities\",\"industry\": \"Utilities - Regulated Electric\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"HPC\", 828): {\n",
				"            \"company_name\": \"Hercules Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Basic Materials\",\"industry\": \"Specialty Chemicals\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"EDS\", 842): {\n",
				"            \"company_name\": \"Electronic Data Systems\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Information Technology Services\",\"exchange\": \"NYSE\"},\n",
				"        (\"TEK\", 861): {\n",
				"            \"company_name\": \"Tektronix Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Semiconductor Equipment & Materials\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"ADCT\", 879): {\n",
				"            \"company_name\": \"ADC Telecommunications Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Communication Equipment\",\"source\": \"tiingo\",\"exchange\": \"NASDAQ\"},\n",
				"        (\"MEDI\", 880): {\n",
				"            \"company_name\": \"MedImmune Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Healthcare\",\"industry\": \"Biotechnology\",\"source\": \"tiingo\",\"exchange\": \"NASDAQ\"},\n",
				"        (\"CMX\", 885): {\n",
				"            \"company_name\": \"Caremark Rx Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Consumer Defensive\",\"industry\": \"Pharmaceutical Retailers\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"LU\", 897): {\n",
				"            \"company_name\": \"Lucent Technologies Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Communication Equipment\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"MERQ\", 924): {\n",
				"            \"company_name\": \"Mercury Interactive Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Software - Application\",\"source\": \"tiingo\",\"exchange\": \"NASDAQ\"},\n",
				"        (\"GP\", 927): {\n",
				"            \"company_name\": \"Georgia-Pacific Corporation\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Basic Materials\",\"industry\": \"Paper & Paper Products\",\"exchange\": \"NYSE\"},\n",
				"        (\"PVN\", 931): {\n",
				"            \"company_name\": \"Providian Financial Corporation\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Banks - Regional\",\"exchange\": \"NYSE\"},\n",
				"        (\"PWER\", 942): {\n",
				"            \"company_name\": \"Power-One, Inc\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Semiconductor Equipment & Materials\",\"exchange\": \"NASDAQ\"},\n",
				"        (\"PSFT\", 943): {\n",
				"            \"company_name\": \"People Soft Inc\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Information Technology Services\",\"exchange\": \"NASDAQ\"},\n",
				"        (\"UPC\", 952): {\n",
				"            \"company_name\": \"Union Planters Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Banks - Regional\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"PCS\", 956): {\n",
				"            \"company_name\": \"Sprint PCS Group\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Communication Services\",\"industry\": \"Telecom Services\",\"exchange\": \"NYSE\"},\n",
				"        (\"NSI\", 995): {\n",
				"            \"company_name\": \"National Service Industries Inc\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Consumer Cyclical\",\"industry\": \"Personal Services\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"OAT\", 1007): {\n",
				"            \"company_name\": \"Quaker Oats Co\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Consumer Defensive\",\"industry\": \"Packaged Foods\",\"exchange\": \"NYSE\"},\n",
				"        (\"H\", 1010): {\n",
				"            \"company_name\": \"Harcourt General Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Consumer Cyclical\",\"industry\": \"Publishing\",\"exchange\": \"NYSE\"},\n",
				"        (\"FPC\", 1032): {\n",
				"            \"company_name\": \"Florida Progress Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Utilities\",\"industry\": \"Utilities - Regulated Electric\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"COMS\", 1047): {\n",
				"            \"company_name\": \"3Com Corp.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Communication Equipment\",\"source\": \"tiingo\",\"exchange\": \"NASDAQ\"},\n",
				"        (\"USW\", 1051): {\n",
				"            \"company_name\": \"US West Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Communication Services\",\"industry\": \"Telecommunications Services\",\"exchange\": \"NYSE\"},\n",
				"        (\"NLV\", 1074): {\n",
				"            \"company_name\": \"NextLevel Systems Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Communication Equipment\",\"exchange\": \"NYSE\"},\n",
				"        (\"LI\", 1077): {\n",
				"            \"company_name\": \"Laidlaw International, Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Industrials\",\"industry\": \"General Transportation\",\"exchange\": \"NYSE\"},\n",
				"        (\"TEN\", 1083): {\n",
				"            \"company_name\": \"Tenneco Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Consumer Cyclical\",\"industry\": \"Auto Parts\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"AR\", 1084): {\n",
				"            \"company_name\": \"Asarco Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Basic Materials\",\"industry\": \"Other Industrial Metals & Mining\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"SNT\", 1085): {\n",
				"            \"company_name\": \"Sonat Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Energy\",\"industry\": \"Oil & Gas Midstream\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"BT\", 1105): {\n",
				"            \"company_name\": \"Bankers Trust Corp.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Banks - Regional\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"AN\", 1117): {\n",
				"            \"company_name\": \"Amoco Corp.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Energy\",\"industry\": \"Oil & Gas Refining & Marketing\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"GRN\", 1119): {\n",
				"            \"company_name\": \"General Reinsurance Corporation\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Reinsurance\",\"exchange\": \"NYSE\"},\n",
				"        (\"AS\", 1120): {\n",
				"            \"company_name\": \"Armco Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Basic Materials\",\"industry\": \"Steel\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"STO\", 1121): {\n",
				"            \"company_name\": \"Stone Container Corp.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Basic Materials\",\"industry\": \"Paper & Paper Products\",\"exchange\": \"NYSE\"},\n",
				"        (\"C\", 1122): {\n",
				"            \"company_name\": \"Chrysler Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Consumer Cyclical\",\"industry\": \"Auto Manufacturers\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"MCIC\", 1130): {\n",
				"            \"company_name\": \"MCI Communications Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Communication Services\",\"industry\": \"Telecommunications Services\",\"exchange\": \"NASDAQ\"},\n",
				"        (\"MST\", 1133): {\n",
				"            \"company_name\": \"Mercantile Stores Inc\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Consumer Cyclical\",\"industry\": \"Department Stores\",\"exchange\": \"NYSE\"},\n",
				"        (\"WAI\", 1134): {\n",
				"            \"company_name\": \"Western Atlas Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Energy\",\"industry\": \"Oil & Gas Equipment & Services\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"BNL\", 1138): {\n",
				"            \"company_name\": \"Beneficial Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Credit Services\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"GNT\", 1140): {\n",
				"            \"company_name\": \"Green Tree Financial Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Mortgage Finance\",\"exchange\": \"NYSE\"},\n",
				"        (\"PET\", 1141): {\n",
				"            \"company_name\": \"Pacific Enterprises\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Utilities\",\"industry\": \"Utilities - Regulated Gas\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"DEC\", 1142): {\n",
				"            \"company_name\": \"Digital Equipment Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Technology\",\"industry\": \"Information Technology Services\",\"exchange\": \"NYSE\"},\n",
				"        (\"CFL\", 1143): {\n",
				"            \"company_name\": \"Corestates Financial Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Banks - Regional\",\"source\": \"tiingo\",\"exchange\": \"NYSE\"},\n",
				"        (\"FG\", 1144): {\n",
				"            \"company_name\": \"USF&G Corp\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Insurance - Life\",\"exchange\": \"NYSE\"},\n",
				"        (\"CBB\", 1150): {\n",
				"            \"company_name\": \"Caliber System Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Industrials\",\"industry\": \"Integrated Freight & Logistics\",\"exchange\": \"NYSE\"},\n",
				"        (\"BBI\", 1152): {\n",
				"            \"company_name\": \"Barnett Banks Inc.\",\"is_delisted\": True,\"description\": None,\n",
				"            \"sector\": \"Financial Services\",\"industry\": \"Banks - Regional\",\"exchange\": \"NYSE\"}\n",
				"    }\n",
				"    key = (ticker, index)\n",
				"    return company_profiles.get(key)\n",
				"\n",
				"\n",
				"\n",
				"\n",
				"\n",
				"\n",
				"#will return the stock exchange(NYSE or NASDAQ) for edge cases or return None\n",
				"def get_stock_exchange_for_edge_cases(index):\n",
				"    exchange_dict = {129:\"NASDAQ\",527:\"NASDAQ\"}\n",
				"    exchange_dict.update({635:\"NASDAQ\",636:\"NYSE\",650:\"NASDAQ\",662:\"NYSE\",683:\"NASDAQ\",691:\"NYSE\",692:\"NASDAQ\",699:\"NYSE\"})\n",
				"    exchange_dict.update({721:\"NASDAQ\",728:\"NASDAQ\",736:\"NYSE\",739:\"NYSE\",744:\"NYSE\",748:\"NASDAQ\",754:\"NYSE\",762:\"NYSE\"\n",
				"                          ,766:\"NYSE\",772:\"NYSE\",781:\"NYSE\",783:\"NYSE\",785:\"NYSE\",787:\"NYSE\"})\n",
				"    exchange_dict.update({800:\"NYSE\",803:\"NYSE\",806:\"NYSE\",818:\"NYSE\",824:\"NYSE\",826:\"NYSE\",827:\"NYSE\",835:\"NYSE\"\n",
				"                          ,838:\"NYSE\",840:\"NYSE\",841:\"NYSE\",848:\"NYSE\",853:\"NYSE\",854:\"NYSE\",859:\"NYSE\",860:\"NYSE\"\n",
				"                          ,863:\"NYSE\",864:\"NYSE\",866:\"NYSE\",868:\"NYSE\",872:\"NASDAQ\",873:\"NYSE\",874:\"NASDAQ\",876:\"NYSE\"\n",
				"                          ,886:\"NYSE\",888:\"NYSE\",889:\"NASDAQ\",890:\"NYSE\",892:\"NYSE\",893:\"NYSE\",898:\"NYSE\"})\n",
				"    exchange_dict.update({901:\"NYSE\",907:\"NYSE\",909:\"NYSE\",911:\"NYSE\",915:\"NASDAQ\",916:\"NYSE\",918:\"NYSE\",923:\"NYSE\"\n",
				"                          ,925:\"NYSE\",930:\"NYSE\",932:\"NYSE\",933:\"NYSE\",935:\"NASDAQ\",938:\"NYSE\",939:\"NYSE\",940:\"NASDAQ\"\n",
				"                          ,941:\"NYSE\",947:\"NYSE\",948:\"NASDAQ\",949:\"NYSE\",953:\"NYSE\",954:\"NYSE\",958:\"NYSE\",960:\"NYSE\"\n",
				"                          ,962:\"NASDAQ\",964:\"NYSE\",968:\"NASDAQ\",976:\"NYSE\",978:\"NYSE\",981:\"NYSE\",982:\"NASDAQ\",983:\"NASDAQ\"\n",
				"                          ,988:\"NYSE\",990:\"NYSE\",991:\"NYSE\",993:\"NYSE\",994:\"NYSE\",996:\"NYSE\",997:\"NYSE\",999:\"NYSE\"})\n",
				"    exchange_dict.update({1000:\"NYSE\",1003:\"NYSE\",1006:\"NYSE\",1015:\"NYSE\",1016:\"NYSE\",1017:\"NYSE\",1018:\"NYSE\",1019:\"NYSE\"\n",
				"                          ,1022:\"NYSE\",1024:\"NYSE\",1027:\"NYSE\",1033:\"NYSE\",1035:\"NYSE\",1036:\"NYSE\",1037:\"NYSE\",1038:\"NYSE\"\n",
				"                          ,1040:\"NYSE\",1043:\"NYSE\",1046:\"NYSE\",1048:\"NYSE\",1052:\"NYSE\",1053:\"NYSE\",1056:\"NYSE\",1057:\"NYSE\"\n",
				"                          ,1058:\"NYSE\",1059:\"NYSE\",1061:\"NYSE\",1063:\"NYSE\",1064:\"NYSE\",1066:\"NYSE\",1067:\"NYSE\",1068:\"NYSE\"\n",
				"                          ,1069:\"NYSE\",1071:\"NYSE\",1073:\"NYSE\",1075:\"NYSE\",1079:\"NYSE\",1081:\"NYSE\",1086:\"NYSE\",1087:\"NYSE\"\n",
				"                          ,1088:\"NYSE\",1089:\"NYSE\",1094:\"NYSE\",1096:\"NYSE\",1097:\"NYSE\",1098:\"NYSE\",1099:\"NYSE\"})\n",
				"    exchange_dict.update({1100:\"NYSE\",1101:\"NASDAQ\",1106:\"NYSE\",1107:\"NYSE\",1110:\"NYSE\",1112:\"NASDAQ\",1114:\"NASDAQ\"\n",
				"                          ,1116:\"NYSE\",1118:\"NYSE\",1123:\"NYSE\",1124:\"NYSE\",1125:\"NYSE\",1126:\"NYSE\",1127:\"NYSE\",1128:\"NYSE\"\n",
				"                          ,1129:\"NYSE\",1131:\"NYSE\",1132:\"NASDAQ\",1135:\"NYSE\",1146:\"NYSE\",1147:\"NYSE\"})\n",
				"    return exchange_dict.get(index)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Company Marketcap Functions"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 6,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"#get market cap data from fmp\n",
				"def get_fmp_market_cap_data(original_ticker, index):\n",
				"    start_year = 2020\n",
				"    end_year = 2024\n",
				"    if index >  570:\n",
				"        start_year = 2016\n",
				"        end_year = 2020\n",
				"    if index > 680:\n",
				"        start_year = 2012\n",
				"        end_year = 2016\n",
				"    if index > 750:\n",
				"        years_to_subtract = ((index - 550) // 100) * 4\n",
				"        start_year = 2020 - years_to_subtract\n",
				"        end_year = 2024 - years_to_subtract\n",
				"    if index > 1200:\n",
				"        start_year = 1922\n",
				"        end_year = 1996       \n",
				"    fmp_market_cap_data = []\n",
				"    while True:\n",
				"        fmp_url = f\"https://financialmodelingprep.com/api/v3/historical-market-capitalization/{original_ticker}?from={start_year}-01-01&to={end_year}-12-31&apikey={apikey}\"\n",
				"        response = requests.get(fmp_url)\n",
				"        result = response.json()\n",
				"        if len(result) == 0:\n",
				"            break\n",
				"        fmp_market_cap_data += result\n",
				"        start_year -= 5\n",
				"        end_year -= 5\n",
				"    fmp_market_cap_data = [{\"date\":data[\"date\"],\"market_cap\":data[\"marketCap\"]} for data in fmp_market_cap_data]\n",
				"    fmp_market_cap_data.reverse() #reverse the list to go from earliest to latest date like tiingo data\n",
				"    return fmp_market_cap_data\n",
				"\n",
				"\n",
				"#get market cap data from tiingo\n",
				"def get_tiingo_market_cap_data(ticker, added_date,marketcap_metadata):\n",
				"    headers = {'Content-Type': 'application/json'}\n",
				"    tiingo_URL = \"https://api.tiingo.com/tiingo/fundamentals/\" + ticker +\"/daily?token=\" + tiingo_token\n",
				"    requestResponse = requests.get(tiingo_URL, headers=headers)\n",
				"    tiingo_market_cap_data = requestResponse.json()\n",
				"    tiingo_market_cap_data = [{\"date\":data[\"date\"].split(\"T\")[0],\"market_cap\":data[\"marketCap\"]} \n",
				"                              for data in tiingo_market_cap_data]\n",
				"    \n",
				"    #get rid of possible market cap data with null market cap values at start\n",
				"    for i, data in enumerate(tiingo_market_cap_data):\n",
				"        if data[\"market_cap\"] != None:\n",
				"            tiingo_market_cap_data = tiingo_market_cap_data[i:]\n",
				"            break\n",
				"\n",
				"    if len(tiingo_market_cap_data) == 0:\n",
				"        print(\"Empty tiingomarket cap data for: \" + ticker)\n",
				"    else: \n",
				"        #if market cap data already has enough data, return it early; else, look into stock price data\n",
				"        first_date_in_market_cap_data = datetime.strptime(tiingo_market_cap_data[0][\"date\"], \"%Y-%m-%d\")\n",
				"        if (first_date_in_market_cap_data <= added_date \n",
				"            or first_date_in_market_cap_data <= datetime.strptime(\"1998-01-02\", \"%Y-%m-%d\")):\n",
				"            return tiingo_market_cap_data\n",
				"\n",
				"        # print(\"Looking at tiingo stock price data: \" + ticker)\n",
				"        tiingo_URL = (\"https://api.tiingo.com/tiingo/daily/\" + ticker + \n",
				"                    \"/prices?startDate=1950-01-02&token=\" + tiingo_token)\n",
				"        requestResponse = requests.get(tiingo_URL, headers=headers)\n",
				"        tiingo_stock_price_data = requestResponse.json()\n",
				"\n",
				"        if (len(tiingo_stock_price_data) > len(tiingo_market_cap_data)):\n",
				"            date_needed = max(added_date,  datetime.strptime(\"1998-01-02\", \"%Y-%m-%d\"))\n",
				"            first_date_in_market_cap_data = datetime.strptime(tiingo_market_cap_data[0][\"date\"], \"%Y-%m-%d\")\n",
				"\n",
				"            nyse = mcal.get_calendar('NYSE')\n",
				"            # Get the market open days within the specified range\n",
				"            missing_trading_days = nyse.valid_days(start_date=date_needed, end_date=first_date_in_market_cap_data)\n",
				"            num_missing_trading_days = len(missing_trading_days)\n",
				"\n",
				"\n",
				"            marketcap_metadata[\"num_trading_days_to_calculate\"] = num_missing_trading_days\n",
				"            if num_missing_trading_days > 250:\n",
				"                print(str(first_date_in_market_cap_data) + \" - \" + str(date_needed))\n",
				"                print(\"\\tTiingo: needed to calculate # of additional trading days: \" + str(num_missing_trading_days))\n",
				"\n",
				"            new_market_cap_data = []\n",
				"            last_stock_market_cap_ratio = None\n",
				"            for daily_stock_price_data in tiingo_stock_price_data:\n",
				"                current_date = datetime.strptime(daily_stock_price_data[\"date\"].split(\"T\")[0], \"%Y-%m-%d\")\n",
				"                if current_date >= first_date_in_market_cap_data:\n",
				"                    last_stock_market_cap_ratio = tiingo_market_cap_data[0][\"market_cap\"] / daily_stock_price_data[\"close\"]\n",
				"                    if current_date != first_date_in_market_cap_data:\n",
				"                        print(\"Same date match not found\")\n",
				"                    break\n",
				"                new_market_cap_data.append(daily_stock_price_data)\n",
				"            new_market_cap_data = [{\"date\": data[\"date\"].split(\"T\")[0]\n",
				"                                    ,\"market_cap\": round(data[\"close\"]*last_stock_market_cap_ratio, 2)} \n",
				"                              for data in new_market_cap_data]\n",
				"            tiingo_market_cap_data = new_market_cap_data + tiingo_market_cap_data\n",
				"\n",
				"            if tiingo_stock_price_data[-1][\"date\"].split(\"T\")[0] != tiingo_market_cap_data[-1][\"date\"]:\n",
				"                print(\"Tiingo data error: Ending Dates aren't the same: \" + ticker)\n",
				"\n",
				"    return tiingo_market_cap_data\n",
				"\n",
				"\n",
				"#4 cases\n",
				"def get_misc_market_cap_data(index, ticker, marketcap_metadata, s3):\n",
				"    bucket_name = 'sp500-historical-analysis-project'\n",
				"    file_key = \"historical_stock_price/\" + str(index) + \"_\" + ticker + \".csv\"\n",
				"    response = s3.get_object(Bucket=bucket_name, Key=file_key) # Get the object from S3\n",
				"    csv_content = response['Body'].read().decode('utf-8') # Read the file content as a string\n",
				"    csv_buffer = StringIO(csv_content) # Use StringIO to convert the string data into a file-like object\n",
				"    data = pd.read_csv(csv_buffer)\n",
				"    marketcaps_dict = {89:51.8, 90:51.8, 162:47, 728:24.4}\n",
				"    if ticker != \"DELL\":\n",
				"        data[\"Price\"] = data[\"Price\"].astype(float)\n",
				"        marketcap_metadata[\"source\"] = \"investing.com\"\n",
				"        marketcap_ratio = marketcaps_dict[index] / float(data.iloc[0][\"Price\"])\n",
				"        data[\"Date\"] = data[\"Date\"].apply(lambda x : x.split(\"/\")[2] + \"-\" + x.split(\"/\")[0] + \"-\" + x.split(\"/\")[1])\n",
				"        data[\"Marketcap\"] = data[\"Price\"].apply(lambda x : round(x * marketcap_ratio * 1000000000, 2))\n",
				"        marketcap_data = []\n",
				"        for i in range(len(data)):\n",
				"            marketcap_data.append({\"date\": data.iloc[i][\"Date\"], \"market_cap\": data.iloc[i][\"Marketcap\"]})\n",
				"        marketcap_data.reverse()\n",
				"        return marketcap_data\n",
				"    else: #for 728, DELL\n",
				"        \n",
				"        marketcap_metadata[\"source\"] = \"https://i.dell.com/sites/csdocuments/Corporate_secure_Documents/en/dell-closing-costs.pdf\"\n",
				"        marketcap_ratio = marketcaps_dict[728] / 13.73\n",
				"\n",
				"        indices =list(data[data[\"Date\"] == \"Please note that these closing prices reflect the Cumulative Split-Adjusted Price.\"].index)\n",
				"        marketcap_data = []\n",
				"        for i in range(len(indices) - 1): #4 columns of data to process, Date, Price, Date2, Price 2\n",
				"            start, stop = indices[i] + 1, indices[i+1]\n",
				"            marketcap_data_part1 = []\n",
				"            marketcap_data_part2 = []\n",
				"            for index in range(start, stop):\n",
				"                date_parts_1 = data.iloc[index][\"Date\"].split(\"/\")\n",
				"                year, month, day = (date_parts_1[2], date_parts_1[0] if int(date_parts_1[0]) >= 10 else \"0\" + date_parts_1[0]\n",
				"                                    ,date_parts_1[1] if int(date_parts_1[1]) >= 10 else \"0\" + date_parts_1[1])\n",
				"                date_1 = year + \"-\" + month + \"-\" + day\n",
				"                marketcap_1 = round(float(float(data.iloc[index][\"Stock Close Price\"]) * marketcap_ratio * 1000000000), 2)\n",
				"                date_parts_2 = data.iloc[index][\"Date.1\"].split(\"/\")\n",
				"                year, month, day = (date_parts_2[2], date_parts_2[0] if int(date_parts_2[0]) >= 10 else \"0\" + date_parts_2[0]\n",
				"                                    ,date_parts_2[1] if int(date_parts_2[1]) >= 10 else \"0\" + date_parts_2[1])\n",
				"                date_2 = year + \"-\" + month + \"-\" + day\n",
				"                marketcap_2 = round(float(float(data.iloc[index][\"Stock Close Price.1\"]) * marketcap_ratio * 1000000000), 2)\n",
				"                marketcap_data_part1.append({\"date\":date_1, \"market_cap\": marketcap_1})\n",
				"                marketcap_data_part2.append({\"date\":date_2, \"market_cap\": marketcap_2})\n",
				"            marketcap_data = marketcap_data + marketcap_data_part1 + marketcap_data_part2 \n",
				"\n",
				"        for index in range(indices[-1]+1, len(data)): #for last part of data, only 2 columns\n",
				"            date_parts = data.iloc[index][\"Date\"].split(\"/\")\n",
				"            year, month, day = (date_parts[2], date_parts[0] if int(date_parts[0]) >= 10 else \"0\" + date_parts[0]\n",
				"                                ,date_parts[1] if int(date_parts[1]) >= 10 else \"0\" + date_parts[1])\n",
				"            date = year + \"-\" + month + \"-\" + day\n",
				"            marketcap = round(float(float(data.iloc[index][\"Stock Close Price\"]) * marketcap_ratio * 1000000000), 2)\n",
				"            marketcap_data.append({\"date\":date, \"market_cap\": marketcap})\n",
				"    return marketcap_data\n",
				"\n",
				"\n",
				"#about 36 uses\n",
				"def get_companiesmarketcap_market_cap_data(index, start_date, end_date, marketcap_metadata):\n",
				"    #modify start date as needed; get later of current start date and start of 1998\n",
				"    start_date_check = max(datetime.strptime(start_date, \"%B %d, %Y\"),  datetime.strptime(\"1998-01-02\", \"%Y-%m-%d\")).__str__()[:10]\n",
				"    if start_date_check == \"1998-01-02\": start_date = \"January 2, 1998\"\n",
				"    #modify end date as needed for current SP 500 companies\n",
				"    if index in [366, 377, 499]: end_date = \"September 30, 2024\"\n",
				"\n",
				"    URL_dict = {366:\"https://companiesmarketcap.com/paramount/marketcap/\", 377:\"https://companiesmarketcap.com/linde/marketcap/\"\n",
				"            ,499:\"https://companiesmarketcap.com/sp-global/marketcap/\"\n",
				"            ,618:\"https://companiesmarketcap.com/monsanto/marketcap/\", 693:\"https://companiesmarketcap.com/noble-corp/marketcap/\"\n",
				"            ,726:\"https://companiesmarketcap.com/jcpenney/marketcap/\", 732:\"https://companiesmarketcap.com/sprint-corporation/marketcap/\"\n",
				"            ,766:\"https://companiesmarketcap.com/national-semiconductor/marketcap/\", 772:\"https://companiesmarketcap.com/qwest-communications-international/marketcap/\"\n",
				"            ,792:\"https://companiesmarketcap.com/sun-microsystems/marketcap/\", 799:\"https://companiesmarketcap.com/schering-plough/marketcap/\"\n",
				"            ,800:\"https://companiesmarketcap.com/wyeth/marketcap/\", 812:\"https://companiesmarketcap.com/noble-corp/marketcap/\"\n",
				"            ,839:\"https://companiesmarketcap.com/lehman-brothers/marketcap/\", 852:\"https://companiesmarketcap.com/bear-stearns/marketcap/\"\n",
				"            ,869:\"https://companiesmarketcap.com/ncr-corporation/marketcap/\", 871:\"https://companiesmarketcap.com/first-data-corporation/marketcap/\"\n",
				"            ,893:\"https://companiesmarketcap.com/bellsouth/marketcap/\", 894:\"https://companiesmarketcap.com/par-technology/marketcap/\"\n",
				"            ,897:\"https://companiesmarketcap.com/lucent-technologies/marketcap/\"\n",
				"            ,907:\"https://companiesmarketcap.com/gateway-inc/marketcap/\", 929:\"https://companiesmarketcap.com/att/marketcap/\"\n",
				"            ,935:\"https://companiesmarketcap.com/nextel-communications/marketcap/\", 940:\"https://companiesmarketcap.com/veritas-technologies/marketcap/\"\n",
				"            ,964:\"https://companiesmarketcap.com/pharmacia/marketcap/\", 966:\"https://companiesmarketcap.com/healthsouth/marketcap/\"\n",
				"            ,975:\"https://companiesmarketcap.com/nortel-networks/marketcap/\", 985:\"https://companiesmarketcap.com/worldcom/marketcap/\"\n",
				"            ,987:\"https://companiesmarketcap.com/compaq-computer/marketcap/\", 996:\"https://companiesmarketcap.com/enron/marketcap/\"\n",
				"            ,998:\"https://companiesmarketcap.com/global-crossing/marketcap/\"\n",
				"            ,1027:\"https://companiesmarketcap.com/seagram/marketcap/\", 1056:\"https://companiesmarketcap.com/warner-lambert/marketcap/\"\n",
				"            ,1058:\"https://companiesmarketcap.com/mediaone-group/marketcap/\", 1068:\"https://companiesmarketcap.com/pharmacia-upjohn/marketcap/\"\n",
				"            ,1122:\"https://companiesmarketcap.com/chrysler-corporation/marketcap/\"\n",
				"            }\n",
				"\n",
				"    page_url = URL_dict[index]\n",
				"    response = requests.get(page_url)\n",
				"    soup = BeautifulSoup(response.content, 'html.parser')\n",
				"    data = soup.find(\"script\",{\"type\": \"text/javascript\"}).string\n",
				"\n",
				"    # Use regex to find the data variable\n",
				"    pattern = re.compile(r\"data\\s*=\\s*(\\[\\{.*?\\}\\]);\")\n",
				"    match = pattern.search(data)\n",
				"    if match:\n",
				"        data = match.group(1)\n",
				"        data = json.loads(data)\n",
				"        for i, point in enumerate(data):\n",
				"            market_cap_in_millions = point[\"m\"]\n",
				"            del data[i]['m']\n",
				"            data[i][\"market_cap\"] = market_cap_in_millions * (10 ** 5) #should be 10 ** 6, but data is off by 10\n",
				"        # print(data[:5], data[-5:])\n",
				"\n",
				"        #get relevant market cap range to return data\n",
				"        # print(start_date, end_date)\n",
				"        nyse = mcal.get_calendar('NYSE') # Create a calendar for the New York Stock Exchange\n",
				"        market_open_days = nyse.valid_days(start_date=start_date, end_date=end_date) # Get the market open days within the specified range\n",
				"        market_cap_data = []\n",
				"        for i, date in enumerate(market_open_days):\n",
				"            month, day, year = date.month, date.day, date.year\n",
				"            if date.month < 10: month = \"0\" + str(month)\n",
				"            if date.day < 10: day = \"0\" + str(day)\n",
				"            date = str(year) + \"-\" + str(month) + \"-\" + str(day)\n",
				"            current_unix_time = int(datetime.strptime(date + \" 00:00:00\", \"%Y-%m-%d %H:%M:%S\").timestamp())\n",
				"\n",
				"            first_data = data[0]\n",
				"            second_data = data[1]\n",
				"            while True: #get correct two date ranges from available data\n",
				"                if len(data) == 2: break\n",
				"                if current_unix_time < first_data[\"d\"] and current_unix_time < second_data[\"d\"]: break\n",
				"\n",
				"                if (first_data[\"d\"] < current_unix_time < second_data[\"d\"]) == False:\n",
				"                    data.pop(0)\n",
				"                    first_data = data[0]\n",
				"                    second_data = data[1]\n",
				"                else:\n",
				"                    break\n",
				"            \n",
				"            #less than available date range\n",
				"            if current_unix_time < first_data[\"d\"] and current_unix_time < second_data[\"d\"]:\n",
				"                market_cap_data.append({\"date\":date, \"market_cap\":round(first_data[\"market_cap\"], 2)})\n",
				"            #between chosen date ranges\n",
				"            elif (first_data[\"d\"] < current_unix_time < second_data[\"d\"]):\n",
				"                #value between 0-1 that tells where you are between the two chosen dates\n",
				"                x = (current_unix_time - first_data[\"d\"]) / (second_data[\"d\"] - first_data[\"d\"])\n",
				"                market_cap_range = second_data[\"market_cap\"] - first_data[\"market_cap\"]\n",
				"                market_cap = round((market_cap_range * x) + first_data[\"market_cap\"], 2) \n",
				"                market_cap_data.append({\"date\":date, \"market_cap\":market_cap})\n",
				"            #larger than avaiable date range\n",
				"            elif current_unix_time > first_data[\"d\"] and current_unix_time > second_data[\"d\"]:\n",
				"                market_cap_data.append({\"date\":date, \"market_cap\":round(second_data[\"market_cap\"], 2)})\n",
				"            else:\n",
				"                print(\"Unknown case\")\n",
				"\n",
				"        marketcap_metadata[\"source\"] = \"companiesmarketcap.com\"\n",
				"        return market_cap_data\n",
				"    else:\n",
				"        print(\"Data not found: companiesmarketcap.com\")\n",
				"\n",
				"\n",
				"#about 25 uses\n",
				"def get_kibot_market_cap_data(index, ticker, start_date, end_date, marketcap_metadata):\n",
				"    marketcap_metadata[\"source\"] = \"kibot\"\n",
				"\n",
				"    if index == 855: ticker = \"HET\" #edge case; changed ticker symbol later; HET -> CZR (Caesar's Entertainment)\n",
				"\n",
				"    #need to fix start and end date to right format: year-month-day (xxxx-xx-xx)\n",
				"    start_date_check = max(datetime.strptime(start_date, \"%B %d, %Y\"),  datetime.strptime(\"1998-01-02\", \"%Y-%m-%d\")).__str__()[:10]\n",
				"    if start_date_check == \"1998-01-02\": start_date = \"January 2, 1998\"\n",
				"    start_date = datetime.strptime(start_date, \"%B %d, %Y\").__str__()[:10]\n",
				"    end_date = datetime.strptime(end_date, \"%B %d, %Y\").__str__()[:10]\n",
				"\n",
				"    authenciation_request = requests.get(\"http://api.kibot.com/?action=login&user=\" + username + \"&password=\" + password)\n",
				"    # print(authenciation_request.text)\n",
				"    headers = [\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
				"    kibot_request = requests.get(\"http://api.kibot.com/?action=history&symbol=MSFT&interval=daily&period=10\")\n",
				"    kibot_request = requests.get(\"http://api.kibot.com/?action=history&symbol=\" + str(ticker) + \"&interval=daily\"\n",
				"                                 + \"&startdate=\" + str(start_date) + \"&enddate=\" + str(end_date))\n",
				"\n",
				"    result_list = kibot_request.text.splitlines()\n",
				"    stock_price_data = []\n",
				"    for line in result_list:\n",
				"        values = line.split(',')\n",
				"        stock_price_data.append(dict(zip(headers, values)))\n",
				"\n",
				"    ending_market_cap_dict = {620:6.11, 646:9, 648:7.8, 656:4, 657:1.6, 658:13.06, 664:14.5, 683:16.34\n",
				"                            , 711:3.65, 725:6.93, 735:23.41, 743:12.05, 788:3.2\n",
				"                            , 804:0.294, 809:1.05, 853:0.69, 854:7.03, 855:17.4, 857:1.82\n",
				"                            , 926:0.8, 967:0.23\n",
				"                            , 1041:5.69, 1071:0.63\n",
				"                            , 1149:2.52}\n",
				"    marketcap_price_ratio = ending_market_cap_dict[index] / float(stock_price_data[-1][\"Close\"])\n",
				"\n",
				"    market_cap_data = []\n",
				"    for data in stock_price_data:\n",
				"        date_data = data[\"Date\"].split(\"/\")\n",
				"        date = date_data[2] + \"-\" + date_data[0] + \"-\" + date_data[1]\n",
				"        market_cap = round(float(data[\"Close\"]) * marketcap_price_ratio * (10 ** 9), 2)\n",
				"        market_cap_data.append({\"date\":date, \"market_cap\":market_cap})\n",
				"    return market_cap_data\n",
				"\n",
				"\n",
				"def get_finchat_market_cap_data(index, ticker, start_date, end_date, marketcap_metadata, s3):\n",
				"    #modify start date as needed; get later of current start date and start of 1998\n",
				"    start_date_check = max(datetime.strptime(start_date, \"%B %d, %Y\"),  datetime.strptime(\"1998-01-02\", \"%Y-%m-%d\")).__str__()[:10]\n",
				"    if start_date_check == \"1998-01-02\": start_date = \"January 2, 1998\"\n",
				"    if end_date == None: end_date = \"September 30, 2024\"\n",
				"\n",
				"    #edge cases\n",
				"    if index == 956: start_date = \"March 13, 2001\" #limited data\n",
				"    if index == 989: start_date = \"March 18, 1999\" #limited data\n",
				"    if index == 1084: end_date = \"November 17, 1999\" #more data than needed\n",
				"    if index == 1086: end_date = \"December 2, 1999\" #more data than needed\n",
				"    if index in [1015, 1148, 1152]: #these will be quickly processed instead of normal function\n",
				"        #for CEN, 1015, 13 days of relevant data; needed\n",
				"        market_caps = None\n",
				"        if index == 1015:\n",
				"            start_date = \"March 14, 2001\"\n",
				"            market_caps = [2.48, 2.26, 2.11, 2.04, 2.19, 2.22, 2.18, 1.89, 1.82, 2.01, 1.97, 1.95, 2.05]\n",
				"        #for ITT, 1148\n",
				"        if index == 1148:\n",
				"            market_caps = [3.69, 3.71, 3.68, 3.62, 3.66, 3.37, 3.62, 3.59, 3.66, 3.66, 3.67, 3.69, 3.62, 3.67, 3.68, 3.56, 3.55, 3.67, 3.74, 3.67\n",
				"            ,3.81, 3.73, 3.74, 3.79, 3.78, 3.86, 3.92, 3.86, 3.81, 3.78, 3.83, 3.83, 3.83, 3.91]\n",
				"        #for BBI, 1152\n",
				"        if index == 1152:\n",
				"            market_caps = [13.92, 14.18, 14.07, 14.07, 13.96, 13.43]\n",
				"        nyse = mcal.get_calendar('NYSE') # Create a calendar for the New York Stock Exchange\n",
				"        market_open_days = nyse.valid_days(start_date=start_date, end_date=end_date) # Get the market open days within the specified range\n",
				"        market_cap_data = []\n",
				"        for i, date in enumerate(market_open_days):\n",
				"            month, day, year = date.month, date.day, date.year\n",
				"            if day < 10: day = \"0\" + str(day)\n",
				"            if month < 10: month = \"0\" + str(month)\n",
				"            date = str(year) + \"-\" + str(month) + \"-\" + str(day)\n",
				"            market_cap_data.append({\"date\":date, \"market_cap\":round(market_caps[i] * (10 ** 9), 2)})\n",
				"        marketcap_metadata[\"image_type\"] = \"screenshot\"\n",
				"        marketcap_metadata[\"source\"] = \"finchat.io\"\n",
				"        return market_cap_data\n",
				"\n",
				"    image_file = \"finchat_market_cap_images/\" + str(index) + \"_\" + ticker + \".png\"\n",
				"    response = s3.get_object(Bucket=bucket_name, Key=image_file) # Get the object from S3\n",
				"    # Read the image content and convert it to a NumPy array\n",
				"    image_content = response['Body'].read()\n",
				"    image_np_array = np.frombuffer(image_content, np.uint8)\n",
				"    image = cv2.imdecode(image_np_array, cv2.IMREAD_COLOR) # Decode the image with OpenCV\n",
				"\n",
				"\n",
				"    # image = cv2.imread(image_file)\n",
				"    \n",
				"    \n",
				"    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
				"    length, height = gray_image.shape[1], gray_image.shape[0]\n",
				"    min_market_cap, max_market_cap =  get_finchat_market_cap_range(index)\n",
				"\n",
				"    reference_list = [] #will be a list representing the image scaled to the proper x-range(date) and y-range(market-caps)\n",
				"    #process the image data to get pixel data scaled properly(x-coord scales to unix time and y-coord scales to market_caps)\n",
				"    if (length == 4000 and height == 1600) or index in [784]:\n",
				"        marketcap_metadata[\"image_type\"] = \"download\"\n",
				"        gray_image = gray_image[130:-209, 20:-50] #basic cropping of image\n",
				"        length, height = gray_image.shape[1], gray_image.shape[0] #get new dimensions\n",
				"        reference_list = process_finchat_image_download(gray_image, length, height, start_date, end_date, min_market_cap, max_market_cap)\n",
				"    else:\n",
				"        marketcap_metadata[\"image_type\"] = \"screenshot\"\n",
				"        reference_list = process_finchat_image_screenshot(gray_image, length, height, start_date, end_date, min_market_cap, max_market_cap)\n",
				"\n",
				"    nyse = mcal.get_calendar('NYSE') # Create a calendar for the New York Stock Exchange\n",
				"    market_open_days = nyse.valid_days(start_date=start_date, end_date=end_date) # Get the market open days within the specified range\n",
				"    market_cap_data = []\n",
				"    stock_price_list = reference_list.copy()\n",
				"    for day in market_open_days:\n",
				"        month, day, year = day.month, day.day, day.year\n",
				"        if day < 10: day = \"0\" + str(day)\n",
				"        if month < 10: month = \"0\" + str(month)\n",
				"        date = str(year) + \"-\" + str(month) + \"-\" + str(day)\n",
				"        unix_time = int(datetime.strptime(date + \" 16:00:00\", \"%Y-%m-%d %H:%M:%S\").timestamp())\n",
				"\n",
				"        market_cap = None\n",
				"        while(True):\n",
				"            if len(stock_price_list) == 0:\n",
				"                break\n",
				"            if len(stock_price_list) == 1: #occurs after last point of list\n",
				"                if abs(unix_time - stock_price_list[0][0]) <= (86400 * 7): #at most a week of time difference\n",
				"                    market_cap = round(stock_price_list[0][1] * 1000000000, 2)\n",
				"                    market_cap_data.append({\"date\":date, \"market_cap\":market_cap})\n",
				"                    break\n",
				"                else:\n",
				"                    print(\"Last date is more than a day apart: \" + date)\n",
				"\n",
				"            if stock_price_list[0][0] <= unix_time <= stock_price_list[1][0]:\n",
				"                ratio = (stock_price_list[1][1] - stock_price_list[0][1]) / (stock_price_list[1][0] - stock_price_list[0][0])\n",
				"                market_cap = (unix_time - stock_price_list[0][0]) * ratio + stock_price_list[0][1]\n",
				"                market_cap = round(market_cap * 1000000000, 2)\n",
				"                market_cap_data.append({\"date\":date, \"market_cap\":market_cap})\n",
				"                break\n",
				"            else:\n",
				"                stock_price_list.pop(0)\n",
				"    marketcap_metadata[\"source\"] = \"finchat.io\"\n",
				"    return market_cap_data\n",
				"\n",
				"\n",
				"def process_finchat_image_download(gray_image, length, height, start_date, end_date, min_market_cap, max_market_cap):\n",
				"    color_frequency = {} #gets the count of each color's pixel count in the image\n",
				"    color_occurences = {} #records the first occurence of a color at each 'x' coordinate {x_0:{color1:y_0, color2:y_1}, x_1...}\n",
				"    for x in range(length):\n",
				"        if color_occurences.get(x) is None: color_occurences[x] = {}\n",
				"        for y in range(height):\n",
				"            color_value = gray_image[y, x]\n",
				"            if color_frequency.get(color_value) is None: color_frequency[color_value] = 0\n",
				"            else: color_frequency[color_value] += 1\n",
				"\n",
				"            if color_occurences[x].get(color_value) is None: color_occurences[x][color_value] = y\n",
				"\n",
				"    #chart should have only 3 major values: black(blackground), grid color(), line color; \n",
				"        # will remove the first two from dictionary; afterward, the line color should have the largest # of occurences\n",
				"    last_y = height - 1\n",
				"    line_color = 105\n",
				"    # print(\"Line color: \" + str(line_color))\n",
				"    # print(color_frequency.get(105))\n",
				"    x_start, x_end = None, None #get the range: start and ending x-coord locations of the stock line \n",
				"    for x_coord in color_occurences:\n",
				"        if line_color in color_occurences[x_coord] and x_start == None:\n",
				"            x_start = x_coord\n",
				"        #after finding start of line, find end of line\n",
				"        if x_start != None and line_color not in color_occurences[x_coord]:\n",
				"            x_end = x_coord - 1\n",
				"            if length - x_end >= 100: #check if line detection ends too early\n",
				"                print(\"Line ended too early?\")\n",
				"                return []\n",
				"            break\n",
				"\n",
				"    #get pixel coordinates(x,y) of the stock line\n",
				"    pixel_coordinates = []\n",
				"    for i in range(x_start,x_end):\n",
				"        x_coord = i - x_start\n",
				"        if color_occurences[i].get(line_color) is None:\n",
				"            print(\"error at: \" + str(i))\n",
				"            break\n",
				"        y_coord = height - color_occurences[i].get(line_color) #need to reverse coordinates\n",
				"        pixel_coordinates.append([x_coord,y_coord]) \n",
				"   \n",
				"    #scale the pixel_coordinates properly to dates(x-asix) and the marketcap range(y-axis)\n",
				"    reference_list = []\n",
				"    added_date = start_date\n",
				"    removed_date = end_date\n",
				"    unix_added_date = int(datetime.strptime(added_date + \" 16:00:00\", \"%B %d, %Y %H:%M:%S\").timestamp())\n",
				"    unix_removed_date = int(datetime.strptime(removed_date + \" 16:00:00\", \"%B %d, %Y %H:%M:%S\").timestamp())\n",
				"    x_slope = (unix_removed_date - unix_added_date) / (x_end - x_start) #new axis\n",
				"    y_slope = (max_market_cap - min_market_cap) / height\n",
				"    for i in range(len(pixel_coordinates)):\n",
				"        temp_x_coord = pixel_coordinates[i][0]\n",
				"        x_coord = x_slope * temp_x_coord + unix_added_date\n",
				"        temp_y_coord = pixel_coordinates[i][1]\n",
				"        y_coord = (y_slope * temp_y_coord) + min_market_cap\n",
				"        reference_list.append([x_coord,y_coord])\n",
				"\n",
				"    return reference_list\n",
				"\n",
				"\n",
				"def process_finchat_image_screenshot(gray_image, length, height, start_date, end_date, min_market_cap, max_market_cap):\n",
				"    #get boundaries for graph, excluding pixels containing the x-axis and y-axis\n",
				"    lower_boundary, left_boundary, right_boundary, top_boundary = None, None, None, None\n",
				"\n",
				"    white_frequency = {} #gets the count of each color's pixel count in the image\n",
				"    white_occurences = {} #records the first occurence of a color at each 'x' coordinate {x_0:{color1:y_0, color2:y_1}, x_1...}\n",
				"    for y in range(round(height*0.6),height):\n",
				"        for x in range(length):\n",
				"            color_value = gray_image[y, x]\n",
				"            if color_value == 255:\n",
				"                if white_frequency.get(y) is None:\n",
				"                    white_frequency[y] = 0\n",
				"                    white_occurences[y] = [x]\n",
				"                else:\n",
				"                    white_frequency[y] += 1\n",
				"                    white_occurences[y].append(x)\n",
				"        if white_frequency.get(y) is not None and white_frequency[y]/length > 0.75: #found the y-axis here; is >=75% white pixels\n",
				"            break\n",
				"\n",
				"    y_values = list(white_occurences.keys())\n",
				"    #the last y_value should be the top layer/y-value of the x-axis\n",
				"    #the second-to-last y_value shoud have values of the x-axis where the axis intersect\n",
				"        #also the lower_boundary, excluding the x-axis\n",
				"    lower_boundary = y_values[-2] #the pixels above the x-axis; y-value\n",
				"    left_boundary = white_occurences[y_values[-2]][-1] + 1 #the pixels after the y-axis; x-value\n",
				"    for y in range(lower_boundary, -1, -1):\n",
				"        color = gray_image[y][left_boundary - 1]\n",
				"        if color != 255:\n",
				"            top_boundary = y + 1\n",
				"            break\n",
				"    for x in reversed(white_occurences[lower_boundary + 1]): #look at pixels on line directly above x-axis in reverse\n",
				"        color = gray_image[lower_boundary][x]\n",
				"        if color != 45:\n",
				"            right_boundary = x\n",
				"            break\n",
				"    \n",
				"    #perform basic checks for boundary locations\n",
				"    if (left_boundary < (0.1*length)) == False: print(\"Possible issue with left boundary: \" + str(left_boundary))\n",
				"    if (right_boundary > (0.9*length)) == False: print(\"Possible issue with right boundary: \" + str(right_boundary))\n",
				"    if (200<top_boundary<400) == False: print(\"Possible issue with upper boundary: \" + str(top_boundary))\n",
				"    if (600<lower_boundary<900) == False: print(\"Possible issue with lower boundary: \" + str(lower_boundary))\n",
				"\n",
				"\n",
				"    #double check y-axis for right market caps based on ticker locations\n",
				"    top = all([gray_image[top_boundary][x] == 255 for x in range(left_boundary - 16, left_boundary)])\n",
				"    bottom = all([gray_image[lower_boundary+1][x] == 255 for x in range(left_boundary - 16, left_boundary)])\n",
				"    #if tickers are not on top and/or bottom, adjustments are needed\n",
				"    if (top and bottom) == False:\n",
				"    #get first two tickers from top to determine ticker interval length; tickers should be at least length 15\n",
				"        num_tickers = 0\n",
				"        last_ticker_y_coord = None\n",
				"        ticker_y_locations = []\n",
				"        for y in range(top_boundary, lower_boundary + 5):\n",
				"            #ticker width can be up to 5(assumed); ignore the succeeding y-coords after finding a ticker\n",
				"            if last_ticker_y_coord != None and y - last_ticker_y_coord < 5: continue\n",
				"            ticker_check = all([gray_image[y][x] == 255 for x in range(left_boundary - 16, left_boundary)])\n",
				"            if ticker_check:\n",
				"                num_tickers += 1\n",
				"                last_ticker_y_coord = y\n",
				"                ticker_y_locations.append(y)\n",
				"        ticker_distances = [ticker_y_locations[i+1] - ticker_y_locations[i] for i in range(len(ticker_y_locations) - 1)]\n",
				"        average_ticker_interval = sum(ticker_distances) / len(ticker_distances) #tickers can have varying pixel distances of 1-5\n",
				"        market_cap_ratio = (max_market_cap - min_market_cap) / len(ticker_distances) #market cap amount per ticker interval\n",
				"        if top == False: #adjust upper market cap\n",
				"            x = abs(top_boundary - ticker_y_locations[0]) / average_ticker_interval #distance reletive to a full ticker interval  \n",
				"            max_market_cap = max_market_cap + (x * market_cap_ratio)\n",
				"        if bottom == False: #adjust lower market cap\n",
				"            x = abs(lower_boundary - ticker_y_locations[-1]) / average_ticker_interval #distance reletive to a full ticker interval  \n",
				"            min_market_cap = min_market_cap - (x * market_cap_ratio)\n",
				"    # print(\"Market caps: \" + str((min_market_cap, max_market_cap)))\n",
				"\n",
				"\n",
				"    #with calculated boundaries, crop the image and do final processing to get reference list\n",
				"    cropped_image = gray_image[top_boundary:lower_boundary, left_boundary:right_boundary]\n",
				"    length = cropped_image.shape[1]\n",
				"    height = cropped_image.shape[0]\n",
				"\n",
				"    pixel_coordinates = []\n",
				"    for x in range(length):\n",
				"        for y in range(height):\n",
				"            if cropped_image[y,x] in [170, 132]: #is the value of green and red after being gray-scaled respectively\n",
				"                pixel_coordinates.append([x,height - y]) #need to reverse y-value since it is read top-down\n",
				"                break\n",
				"\n",
				"    reference_list = []\n",
				"\n",
				"    unix_added_date = int(datetime.strptime(start_date + \" 16:00:00\", \"%B %d, %Y %H:%M:%S\").timestamp())\n",
				"    unix_removed_date = int(datetime.strptime(end_date + \" 16:00:00\", \"%B %d, %Y %H:%M:%S\").timestamp())\n",
				"    x_slope = (unix_removed_date - unix_added_date) / length #new axis\n",
				"    y_slope = (max_market_cap - min_market_cap) / height\n",
				"    for i in range(len(pixel_coordinates)):\n",
				"        temp_x_coord = pixel_coordinates[i][0]\n",
				"        x_coord = x_slope * temp_x_coord + unix_added_date\n",
				"        temp_y_coord = pixel_coordinates[i][1]\n",
				"        y_coord = (y_slope * temp_y_coord) + min_market_cap\n",
				"        reference_list.append([x_coord,y_coord])\n",
				"    return reference_list\n",
				"\n",
				"\n",
				"#return the min, max of the marketcap range in the finchat image \n",
				"def get_finchat_market_cap_range(index):\n",
				"    #store min and max of y-axis\n",
				"    #will make code to double-check/adjust for screenshotted data\n",
				"    finchat_download_dict = {545:(15,60), 670:(3,12), 680:(0,45)}\n",
				"    finchat_screenshot_dict = {117:(0,40), 286:(0,40), 586:(0,40), 595:(5,20), 609:(0,40), 612:(0,15), 649:(5,25), 652:(10,30), 659:(0, 250), 660:(0,140) \n",
				"                            ,662:(2,7), 679:(0, 70), 691:(2,14), 695:(0,70)}\n",
				"    #700s, fixed 767 image\n",
				"    finchat_download_dict.update({721:(1,14), 727:(2,26), 737:(0,11), 743:(7,14), 754:(5,13), 762:(0,24), 765:(3.75,6.5)\n",
				"                                ,767:(0,14), 769:(0,8), 771:(2,24), 782:(2,18), 784:(3,14)})\n",
				"    finchat_screenshot_dict.update({714:(0,35), 716:(0,30), 718:(2,16), 731:(5,20), 733:(0,20), 744:(2,14), 747:(0,20), 749:(0,15)\n",
				"                                    ,750:(5,20), 752:(0,10), 753:(0,40), 756:(10,35), 757:(5,20), 758:(0,15), 759:(0,35)\n",
				"                                    ,761:(0,8), 770:(0,15), 774:(0,12), 775:(2,12), 776:(0.5,3), 780:(2,12), 781:(1,5)\n",
				"                                    ,786:(2,16), 787:(2,8), 790:(10,40), 791:(3,9), 797:(0,15)})\n",
				"    #800s\n",
				"    finchat_download_dict.update({806:(3,11), 861:(0,4.5), 867:(6,15), 868:(0,35), 883:(1,8)})\n",
				"    finchat_screenshot_dict.update({801:(2,12), 803:(0,10), 810:(4,16), 817:(2,14), 818:(2,12), 819:(20,100), 820:(0,120)\n",
				"                                    ,821:(5,30), 822:(4,8), 824:(1,7), 826:(0,40), 827:(20,55), 828:(1,5), 835:(10,20), 838:(2,9)\n",
				"                                    ,842:(5,40), 847:(5,30), 848:(1,4.5), 850:(0,10), 859:(2,6), 860:(10,30), 862:(1,5), 863:(1,5)\n",
				"                                    ,864:(0,8), 866:(0,40), 872:(5,11), 873:(4,8), 874:(2,14), 876:(10,25), 877:(0,7), 879:(0,40)\n",
				"                                    ,880:(5,20), 881:(4,16), 884:(4,14), 885:(15,30), 886:(0,30), 887:(4,7), 888:(1,2), 889:(2,10)\n",
				"                                    ,890:(10,22), 891:(0,20), 892:(2,8), 895:(1,4), 898:(4,16)})\n",
				"    #900s\n",
				"    finchat_download_dict.update({901:(3,12), 903:(3,11), 904:(0.25,3.75), 905:(2,26), 910:(3,6.5), 911:(1.5,5), 914:(6,30)\n",
				"                                ,915:(1,13), 916:(2,10), 917:(0,7), 918:(0,40), 919:(5,8.5), 922:(0,55), 923:(0,4), 925:(8,40)\n",
				"                                ,927:(1,14), 931:(0,20), 932:(20,75), 933:(4,17), 937:(5,19), 939:(0.75,3.5), 941:(4,26)\n",
				"                                ,943:(2,16), 947:(2,22), 948:(2,16), 949:(5,55), 950:(3,11), 952:(3,7.5), 953:(20,80), 955:(7,15)\n",
				"                                ,956:(0,30), 958:(15,55), 960:(2,20), 962:(0.75,4), 968:(0.5,5), 969:(3,9), 973:(0,40), 982:(8,18)\n",
				"                                ,989:(1.9,3.1), 990:(2,5), 993:(0.75,3.25), 994:(4,13), 995:(0.5,2.75), 997:(2.5,6.5), 999:(22,42)})\n",
				"    finchat_screenshot_dict.update({900:(1,5), 912:(10,25), 921:(0,15), 924:(2,14), 930:(0,14), 936:(4,12), 938:(2,10), 942:(0,8)\n",
				"                                    ,951:(0.5,4), 954:(0.5,4), 963:(0,2.5), 965:(10,35), 971:(12,20), 983:(0,14), 988:(2,7)})\n",
				"    #1000s, fixed 1078\n",
				"    finchat_download_dict.update({1000:(3,9), 1007:(5,14), 1011:(2,14), 1016:(2.5,6.5), 1017:(3,10), 1019:(4,22), 1022:(0.3,1.2)\n",
				"                                ,1023:(0.3,1.3), 1025:(6,15), 1032:(3.8,5.6), 1033:(3,12), 1034:(2,20), 1036:(4,13), 1037:(3.5,6)\n",
				"                                ,1038:(0.7,1.8), 1039:(6,10.5), 1040:(1.2,3.4), 1042:(10,21), 1043:(2.6,4.6), 1044:(0.7,1.7)\n",
				"                                ,1046:(2.5,5.75), 1049:(1,7), 1052:(40,80), 1057:(2,8), 1060:(2.5,6.5), 1063:(1.75,5.25)\n",
				"                                ,1064:(0.55,1.05), 1065:(2.25,5.25), 1066:(10,55), 1067:(16,34), 1073:(3.75,6.75), 1075:(3.5,8.5)\n",
				"                                ,1078:(45,90), 1080:(1.4,3.2), 1081:(1,5.5), 1084:(0.4,1.3), 1085:(2.5,5.25), 1086:(0.7,2)\n",
				"                                ,1087:(0.3,1.3), 1088:(40,90), 1089:(4,11), 1090:(7,18), 1091:(0,2.75), 1092:(3,11), 1094:(1.5,4)\n",
				"                                ,1095:(0.2,1.8), 1097:(4,8), 1098:(5.5,10)})\n",
				"    finchat_screenshot_dict.update({1001:(20,70), 1003:(10,25), 1006:(2,10), 1009:(0.6,1.8), 1010:(2.5,5), 1013:(1,7), 1014:(0.6,1.8)\n",
				"                                    ,1018:(4,10), 1021:(1.5,5), 1045:(0.6,1.6), 1047:(5,40), 1050:(4,12), 1054:(1,5), 1059:(3,7)\n",
				"                                    ,1061:(1,2.5), 1069:(0.5,2), 1079:(5,9), 1082:(1.5,5), 1083:(2,9), 1093:(0.015,0.05)})\n",
				"    #1100s, fixed 1100, 1146\n",
				"    finchat_download_dict.update({1100:(15,70), 1103:(2.5,5.5), 1105:(4,14), 1106:(0.7,1.6), 1107:(5,11), 1108:(2,6.5), 1109:(0.4,2.2)\n",
				"                                ,1110:(5,13), 1111:(3,6), 1113:(1,3), 1114:(8,17), 1117:(36,60), 1119:(14,21), 1120:(0.25,0.8)\n",
				"                                ,1125:(1.8,4), 1126:(17,29), 1127:(4,10), 1128:(4,10), 1129:(1.4,2.7), 1130:(28,52), 1131:(4.5,8.5)\n",
				"                                ,1133:(2.1,3), 1136:(1.9,2.7), 1137:(2.1,3.4), 1138:(3,9), 1140:(2,6.5), 1142:(4.5,9.5)\n",
				"                                ,1146:(1.52,1.72), 1147:(0.43,0.7)})\n",
				"    finchat_screenshot_dict.update({1101:(40,120), 1102:(5,12), 1118:(1.5,3.5), 1121:(1,3), 1123:(40,90), 1132:(2,4.5), 1134:(3,5.5)\n",
				"                                    ,1135:(7,14), 1139:(0.8,1.6), 1141:(2.8,3.8), 1143:(14,22), 1144:(2.2,3.2), 1145:(0.4,0.6)\n",
				"                                    ,1150:(1.8,2.3)})\n",
				"\n",
				"    market_cap_range = finchat_download_dict.get(index)\n",
				"    if market_cap_range == None: market_cap_range = finchat_screenshot_dict.get(index)\n",
				"    if market_cap_range == None: print(\"Error: Market cap range not found for finchat image: \" + str(index)) \n",
				"    return market_cap_range"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Main Functions"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 22,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"def get_company_data(tiingo_ticker, company_profile, company_name, meta_data_list, original_ticker, index, s3):\n",
				"    misc_company_metadata = get_company_metadata_for_edge_cases(original_ticker,index)\n",
				"    if misc_company_metadata != None:\n",
				"        company_profile.update(misc_company_metadata)\n",
				"    else:\n",
				"        got_tiingo_data = get_tiingo_company_regular_data(tiingo_ticker, company_name, company_profile)\n",
				"        got_tiingo_metadata = (get_tiingo_company_metadata(tiingo_ticker, company_profile, meta_data_list) \n",
				"                            if got_tiingo_data == True else False)\n",
				"        if got_tiingo_metadata == False:\n",
				"            get_fmp_metadata(original_ticker, company_name, company_profile, index)\n",
				"\n",
				"    if company_profile.get(\"exchange\") not in [\"NYSE\",\"NASDAQ\"] : company_profile[\"exchange\"] = get_stock_exchange_for_edge_cases(index)\n",
				"    if company_profile.get(\"sector\") == None or company_profile.get(\"industry\") == None:\n",
				"        print(\"Missing sector and industry in profile data: \" + original_ticker)\n",
				"    if company_profile.get(\"exchange\") not in [\"NYSE\",\"NASDAQ\"]:\n",
				"        print(\"Missing exchange(NYSE, NASDAQ) in profile data: \" + original_ticker)\n",
				"\n",
				"    file_path = \"company_profiles/\" + str(index) + \"_\" + original_ticker + \".json\"\n",
				"    json_string = json.dumps(company_profile, indent=4)\n",
				"    s3.put_object(Bucket=bucket_name, Key=file_path, Body=json_string)\n",
				"    return company_profile"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 16,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"def get_market_cap_data(ticker, original_ticker, index, added_date, removal_date, company_name, s3):\n",
				"    marketcap_metadata = {\"index\":index,\"ticker\":original_ticker} #used to store where we get our data source\n",
				"    market_cap_data = []\n",
				"\n",
				"    #need to double-check that first day and last_day are valid (not a weekend or holiday); fix if needed\n",
				"    date1 = max(datetime.strptime(added_date, \"%B %d, %Y\"), datetime.strptime(\"January 2, 1998\", \"%B %d, %Y\")).__str__()[:10]\n",
				"    date2 = (datetime.strptime(\"September 30, 2024\", \"%B %d, %Y\").__str__()[:10] if removal_date == None\n",
				"                       else datetime.strptime(removal_date, \"%B %d, %Y\").__str__()[:10])\n",
				"    nyse = mcal.get_calendar('NYSE')\n",
				"    valid_trading_days = nyse.valid_days(start_date=date1, end_date=date2)   \n",
				"    first_day_needed = valid_trading_days[0].date().__str__()\n",
				"    last_day_needed = valid_trading_days[-1].date().__str__()\n",
				"\n",
				"    finchat_download_list = [545, 670, 680, 721, 727, 737, 743, 754, 762, 765, 767, 769, 771, 782, 784, 806, 861, 867, 868, 883, 901, 903, 904, 905, 910, 911, 914, 915, 916, 917, 918, 919, 922, 923, 925, 927, 931, 932, 933, 937, 939, 941, 943, 947, 948, 949, 950, 952, 953, 955, 956, 958, 960, 962, 968, 969, 973, 982, 989, 990, 993, 994, 995, 997, 999, 1000, 1007, 1011, 1016, 1017, 1019, 1022, 1023, 1025, 1032, 1033, 1034, 1036, 1037, 1038, 1039, 1040, 1042, 1043, 1044, 1046, 1049, 1052, 1057, 1060, 1063, 1064, 1065, 1066, 1067, 1073, 1075, 1078, 1080, 1081, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1094, 1095, 1097, 1098, 1100, 1103, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1113, 1114, 1117, 1119, 1120, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1133, 1136, 1137, 1138, 1140, 1142, 1146, 1147]\n",
				"    finchat_screenshot_list = [117, 286, 586, 595, 609, 612, 649, 652, 659, 660, 662, 679, 691, 695, 714, 716, 718, 731, 733, 744, 747, 749, 750, 752, 753, 756, 757, 758, 759, 761, 770, 774, 775, 776, 780, 781, 786, 787, 790, 791, 797, 801, 803, 810, 817, 818, 819, 820, 821, 822, 824, 826, 827, 828, 835, 838, 842, 847, 848, 850, 859, 860, 862, 863, 864, 866, 872, 873, 874, 876, 877, 879, 880, 881, 884, 885, 886, 887, 888, 889, 890, 891, 892, 895, 898, 900, 912, 921, 924, 930, 936, 938, 942, 951, 954, 963, 965, 971, 983, 988, 1001, 1003, 1006, 1009, 1010, 1013, 1014, 1018, 1021, 1045, 1047, 1050, 1054, 1059, 1061, 1069, 1079, 1082, 1083, 1093, 1101, 1102, 1118, 1121, 1123, 1132, 1134, 1135, 1139, 1141, 1143, 1144, 1145, 1150]\n",
				"    companiesmarketcap_list = [366, 377, 499, 618, 693, 726, 732, 766, 772, 792, 799, 800, 812, 839, 852, 869, 871, 893, 894, 897, 907, 929, 935, 940, 964, 966, 975, 985, 987, 996, 998, 1027, 1056, 1058, 1068, 1122]\n",
				"    kibot_list = [620, 646, 648, 656, 657, 658, 664, 683, 711, 725, 735, 743, 788, 804, 809, 853, 854, 855, 857, 926, 967, 1041, 1071, 1149]\n",
				"\n",
				"    #edge case: 728 DELL\n",
				"    if index == 728:\n",
				"        market_cap_data = get_misc_market_cap_data(index, original_ticker, marketcap_metadata, s3)\n",
				"    #finchat.io\n",
				"    elif index in ([1015, 1148, 1152] + finchat_download_list + finchat_screenshot_list):\n",
				"        market_cap_data = get_finchat_market_cap_data(index, original_ticker, added_date, removal_date, marketcap_metadata, s3)\n",
				"    #companiesmarketcap.com\n",
				"    elif index in companiesmarketcap_list:\n",
				"        market_cap_data = get_companiesmarketcap_market_cap_data(index, added_date, removal_date, marketcap_metadata)\n",
				"    #kibot.com\n",
				"    elif index in kibot_list:\n",
				"        market_cap_data = get_kibot_market_cap_data(index,original_ticker,added_date,removal_date, marketcap_metadata)\n",
				"    #tiingo and fmp\n",
				"    else:\n",
				"        #format: January 21, 2012\n",
				"        added_date = datetime.strptime(added_date, \"%B %d, %Y\") \n",
				"        removal_date = (datetime.strptime(removal_date, \"%B %d, %Y\") if removal_date != None \n",
				"                        else datetime.strptime(\"September 30, 2024\", \"%B %d, %Y\"))\n",
				"        min_date_needed = max(added_date,  datetime.strptime(\"1998-01-02\", \"%Y-%m-%d\"))\n",
				"        tiingo_market_cap_data = []\n",
				"        fmp_market_cap_data = []\n",
				"        #get market cap data from tiingo\n",
				"        if get_tiingo_company_regular_data(ticker,company_name,{}):\n",
				"            tiingo_market_cap_data = get_tiingo_market_cap_data(ticker, added_date,marketcap_metadata)\n",
				"            #filter tiingo market cap data to filter out NULLs and unneeded dates\n",
				"            tiingo_market_cap_data = [val for val in tiingo_market_cap_data \n",
				"                                    if val[\"market_cap\"] != None and\n",
				"                                    min_date_needed <= datetime.strptime(val[\"date\"], \"%Y-%m-%d\") <= removal_date]\n",
				"        #get fmp market cap data if tiingo data is empty or starts after \"Added Date\"\n",
				"        if len(tiingo_market_cap_data) == 0 or marketcap_metadata.get(\"num_trading_days_to_calculate\") not in [None,0]:\n",
				"            if get_fmp_metadata(original_ticker,company_name,{},index):\n",
				"                fmp_market_cap_data = get_fmp_market_cap_data(original_ticker,index)\n",
				"                #filter fmp market cap data to filter out NULLs and unneeded dates\n",
				"                fmp_market_cap_data = [val for val in fmp_market_cap_data\n",
				"                                        if val[\"market_cap\"] != None and\n",
				"                                        min_date_needed <= datetime.strptime(val[\"date\"], \"%Y-%m-%d\") <= removal_date]\n",
				"        #decide whether to use fmp or tiingo data      \n",
				"        tiingo_has_more_data = len(fmp_market_cap_data) <= len(tiingo_market_cap_data)\n",
				"        num_days = len(fmp_market_cap_data) - len(tiingo_market_cap_data)\n",
				"        if marketcap_metadata.get(\"num_trading_days_to_calculate\"): #consider fmp, if tiingo has too many calculations done\n",
				"            tiingo_has_more_data = (len(fmp_market_cap_data) < (len(tiingo_market_cap_data) - marketcap_metadata[\"num_trading_days_to_calculate\"])\n",
				"                                        or len(fmp_market_cap_data) == 0)\n",
				"            num_days = len(fmp_market_cap_data) - (len(tiingo_market_cap_data) - marketcap_metadata[\"num_trading_days_to_calculate\"])\n",
				"        if tiingo_has_more_data == False:\n",
				"            print(\"Using fmp market data; more by: \" + str(num_days))\n",
				"            marketcap_metadata[\"source\"] = \"fmp\"\n",
				"            if marketcap_metadata.get(\"num_trading_days_to_calculate\"): del marketcap_metadata[\"num_trading_days_to_calculate\"]\n",
				"        else:\n",
				"            marketcap_metadata[\"source\"] = \"tiingo\"\n",
				"        market_cap_data = tiingo_market_cap_data if tiingo_has_more_data else fmp_market_cap_data\n",
				"\n",
				"    # add more data from investing.com for these 3 cases\n",
				"    if index in [89,90,162]: \n",
				"        add_info = {}\n",
				"        additional_marketcap_data = get_misc_market_cap_data(index, original_ticker, add_info, s3)\n",
				"        market_cap_data = additional_marketcap_data + market_cap_data\n",
				"        marketcap_metadata[\"source\"] += \" + \" + add_info[\"source\"]\n",
				"\n",
				"    #handle marketcap metadata\n",
				"    if len(market_cap_data) > 0:\n",
				"        marketcap_metadata[\"first_day_have_vs_needed\"] = market_cap_data[0][\"date\"] + \" : \" + first_day_needed\n",
				"        marketcap_metadata[\"last_day_have_vs_needed\"] = market_cap_data[-1][\"date\"] + \" : \" + last_day_needed\n",
				"\n",
				"        if type(added_date) == str:\n",
				"            added_date = datetime.strptime(added_date, \"%B %d, %Y\") #format: January 1, 2005\n",
				"        if type(removal_date) == str:    \n",
				"            removal_date = datetime.strptime(removal_date, \"%B %d, %Y\") \n",
				"        \n",
				"        first_date_in_data = datetime.strptime(market_cap_data[0][\"date\"], \"%Y-%m-%d\") #format: 2006-01-31\n",
				"        last_date_in_data = datetime.strptime(market_cap_data[-1][\"date\"], \"%Y-%m-%d\")\n",
				"\n",
				"        min_date_needed = datetime.strptime(first_day_needed, \"%Y-%m-%d\")\n",
				"        if min_date_needed < first_date_in_data:\n",
				"            missing_days = nyse.valid_days(start_date=min_date_needed, end_date=first_date_in_data)\n",
				"            if str(min_date_needed.date()) == str(missing_days[0].date()): #exclude first day if same \n",
				"                missing_days = missing_days[1:]\n",
				"            days_between = len(missing_days)\n",
				"            if len(missing_days) > 0:\n",
				"                print(first_day_needed + \" : \" + first_date_in_data.date().__str__())\n",
				"                print(\"Missing days of earlier data for market cap: \" + str(days_between))   \n",
				"                marketcap_metadata[\"missing_num_days_before\"] = days_between\n",
				"        if last_date_in_data < datetime.strptime(last_day_needed, \"%Y-%m-%d\"):\n",
				"            missing_days = nyse.valid_days(start_date=last_date_in_data, end_date=last_day_needed)\n",
				"            if str(last_date_in_data.date()) == str(missing_days[0].date()): #exclude first day if same \n",
				"                missing_days = missing_days[1:]\n",
				"            days_between = len(missing_days)\n",
				"            if days_between > 0:\n",
				"                print(last_date_in_data.date().__str__() + \" : \" + last_day_needed)\n",
				"                print(\"Missing days of later data for market cap: \" + str(days_between))\n",
				"                marketcap_metadata[\"missing_num_days_after\"] = days_between\n",
				"    else:\n",
				"        marketcap_metadata[\"is_empty\"] = True\n",
				"        print(\"No market cap data found: \" + ticker)\n",
				"\n",
				"    marketcap_metadata[\"num_of_days_data\"] = len(market_cap_data)\n",
				"\n",
				"    #store market cap data\n",
				"    file_path = \"company_market_cap_data/\" + str(index) + \"_\" + original_ticker + \".json\"\n",
				"    json_string = json.dumps(market_cap_data, indent=4)\n",
				"    s3.put_object(Bucket=bucket_name, Key=file_path, Body=json_string)\n",
				"    \n",
				"    \n",
				"    #store origin of market cap data\n",
				"    file_path = \"market_cap_metadata/\" + str(index) + \"_\" + original_ticker + \".json\"\n",
				"    json_string = json.dumps(marketcap_metadata, indent=4)\n",
				"    s3.put_object(Bucket=bucket_name, Key=file_path, Body=json_string)\n",
				"    \n",
				"    return market_cap_data"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 17,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"def get_tiingo_ticker(ticker, i):\n",
				"    #some delisted or moved stocks have modified tickers for tiingo\n",
				"    #500-600\n",
				"    if 500<=i<600:\n",
				"        if ticker == \"WRK\":     ticker = \"WRK-W\"\n",
				"        if ticker == \"FRC\":     ticker = \"FRCB\" \n",
				"        if ticker == \"SIVB\":    ticker = \"SIVBQ\" \n",
				"        if ticker == \"STI\":     ticker = \"STI-WS-B\"\n",
				"        if ticker == \"INFO\":    ticker = \"MRKT\"\n",
				"    #600-700    \n",
				"    if 600<=i<700:\n",
				"        if ticker == \"XL\":      ticker = \"XLGLF\"\n",
				"        if ticker == \"WYND\":    ticker = \"WYN\"\n",
				"        if ticker == \"BBBY\":    ticker = \"BBBYQ\"\n",
				"        if ticker == \"MNK\":     ticker = \"MNKKQ\"\n",
				"        if ticker == \"ENDP\":    ticker = \"ENDPQ\"\n",
				"        if ticker == \"SE\":      ticker = \"SE1\"\n",
				"        if ticker == \"ALTR\":    ticker = \"ALTR1\"\n",
				"        if ticker == \"PLL\":     ticker = \"PLL1\"\n",
				"        if ticker == \"DTV\":     ticker = \"DTV1\"\n",
				"        if ticker == \"WIN\":     ticker = \"WINMQ\"\n",
				"    #700-800\n",
				"    if 700<=i<800:\n",
				"        if ticker == \"LIFE\":    ticker = \"LIFE2\"\n",
				"        if ticker == \"DELL\":    ticker = \"DELL1\"\n",
				"        if ticker == \"BIG\":     ticker = \"BIGGQ\"\n",
				"        if ticker == \"DF\":      ticker = \"DFODQ\"\n",
				"        if ticker == \"SUN\":     ticker = \"SUN1\"\n",
				"        if ticker == \"ANR\":     ticker = \"ANRZQ\"\n",
				"        if ticker == \"SHLD\":    ticker = \"SHLDQ\"\n",
				"        if ticker == \"MMI\":     ticker = \"MMI1\"\n",
				"        if ticker == \"NSM\":     ticker = \"NSM1\"\n",
				"        if ticker == \"Q\":       ticker = \"Q1\"\n",
				"        if ticker == \"MIL\":     ticker = \"MIL1\"\n",
				"    #800-900\n",
				"    if 800<=i<900:\n",
				"        if ticker == \"CTX\":     ticker = \"CTX1\"\n",
				"        if ticker == \"EQ\":      ticker = \"EQ1\"\n",
				"        if ticker == \"WFT\":     ticker = \"WFTIQ\"\n",
				"        if ticker == \"UST\":     ticker = \"UST1\"\n",
				"        if ticker == \"WB\":      ticker = \"WB2\"\n",
				"        if ticker == \"ABI\":     ticker = \"ABI1\"\n",
				"        if ticker == \"BUD\":     ticker = \"BUD1\"\n",
				"        if ticker == \"SAF\":     ticker = \"SAF2\"\n",
				"        if ticker == \"OMX\":     ticker = \"OMX1\"\n",
				"        if ticker == \"BSC\":     ticker = \"BSC1\"\n",
				"        if ticker == \"CC\":      ticker = \"CCTYQ\"\n",
				"        if ticker == \"CBH\":     ticker = \"CBH1\"\n",
				"        if ticker == \"AT\":      ticker = \"AT1\"\n",
				"        if ticker == \"AV\":      ticker = \"AV1\"\n",
				"        if ticker == \"PD\":      ticker = \"PD1\"\n",
				"        if ticker == \"FSLB\":    ticker = \"FSL-B\"\n",
				"    #900-1000\n",
				"    if 900<=i<1000:\n",
				"        if ticker == \"ACV\":     ticker = \"ACV1\"\n",
				"        if ticker == \"ASO\":     ticker = \"ASO1\"\n",
				"        if ticker == \"EC\":      ticker = \"EC1\"\n",
				"        if ticker == \"CHIR\":    ticker = \"CHIR1\"\n",
				"        if ticker == \"BR\":      ticker = \"BR1\"\n",
				"        if ticker == \"JP\":      ticker = \"JP1\"\n",
				"        if ticker == \"DPH\":     ticker = \"DPHIQ\"\n",
				"        if ticker == \"G\":       ticker = \"G1\"\n",
				"        if ticker == \"SDS\":     ticker = \"SDS1\"\n",
				"        if ticker == \"VRTS\":    ticker = \"VRTS1\"\n",
				"        if ticker == \"S\":       ticker = \"S1\"\n",
				"        if ticker == \"WLP\":     ticker = \"WLP1\"\n",
				"        if ticker == \"CF\":      ticker = \"CF1\"\n",
				"        if ticker == \"ONE\":     ticker = \"ONE1\"\n",
				"        if ticker == \"AM\":      ticker = \"AM1\"\n",
				"        if ticker == \"TAP.B\":   ticker = \"TAP-B\"\n",
				"        if ticker == \"TUP\":     ticker = \"TUPBQ\"\n",
				"        if ticker == \"CE\":      ticker = \"CE1\"\n",
				"        if ticker == \"BGEN\":    ticker = \"BIIB\"  #merger in 2003;reentered SP500 directly after\n",
				"        if ticker == \"HI\":      ticker = \"HI1\"\n",
				"        if ticker == \"AMR\":     ticker = \"AAMRQ\"\n",
				"        if ticker == \"COC.B\":   ticker = \"COC-B\"\n",
				"        if ticker == \"NT\":      ticker = \"NRTLQ\"\n",
				"        if ticker == \"AL\":      ticker = \"AL1\"\n",
				"        if ticker == \"CNXT\":    ticker = \"CNXT1\"\n",
				"        if ticker == \"U\":       ticker = \"UAIRQ\"\n",
				"        if ticker == \"WCOM\":    ticker = \"WCOEQ\"\n",
				"        if ticker == \"WLL\":     ticker = \"WLL1\"\n",
				"        if ticker == \"NMK\":     ticker = \"NMK1\"\n",
				"        if ticker == \"MEA\":     ticker = \"MEA1\"\n",
				"        if ticker == \"TX\":      ticker = \"TX1\"\n",
				"    #1000-1100\n",
				"    if 1000<=i<1100:\n",
				"        if ticker == \"WB\":      ticker = \"WB2\" #also in 800s\n",
				"        if ticker == \"AGC\":     ticker = \"AGC1\"\n",
				"        if ticker == \"AZA.A\":   ticker = \"AZA-A\"\n",
				"        if ticker == \"CEN\":     ticker = \"CEN1\"\n",
				"        if ticker == \"SUB\":     ticker = \"SUB1\"\n",
				"        if ticker == \"UK\":      ticker = \"UK1\"\n",
				"        if ticker == \"SMI\":     ticker = \"SMI1\"\n",
				"        if ticker == \"VO\":      ticker = \"VO1\"\n",
				"        if ticker == \"AFS.A\":   ticker = \"AFS-A\"\n",
				"        if ticker == \"SEG\":     ticker = \"STX\" #relisted in NASDAQ from NYSE\n",
				"        if ticker == \"CG\":      ticker = \"CG1\"\n",
				"        if ticker == \"EFU\":     ticker = \"EFU1\"\n",
				"        if ticker == \"BFO\":     ticker = \"BFO1\"\n",
				"        if ticker == \"GAP\":     ticker = \"GAPTQ\"\n",
				"        if ticker == \"RAD\":     ticker = \"RADCQ\" #unneccessary, but for testing; has fmp data as well\n",
				"        if ticker == \"GTE\":     ticker = \"GTE1\"\n",
				"        if ticker == \"MZ\":      ticker = \"MZIAQ\"\n",
				"        if ticker == \"CHA\":     ticker = \"CHA1\"\n",
				"        if ticker == \"UMG\":     ticker = \"USW\" #incorrect or older symbol? using usw for something else 1051\n",
				"        if ticker == \"CSR\":     ticker = \"CSR1\"\n",
				"        if ticker == \"TMC.A\":   ticker = \"TMC-A\" \n",
				"        if ticker == \"MIR\":     ticker = \"MIR1\"\n",
				"        if ticker == \"RLM\":     ticker = \"RLM1\"\n",
				"        if ticker == \"CBS\":     ticker = \"CBS1\"\n",
				"        if ticker == \"ARC\":     ticker = \"ARC1\"\n",
				"        if ticker == \"PBY\":     ticker = \"PBY1\"\n",
				"        if ticker == \"FLE\":     ticker = \"FLTWQ\"\n",
				"        if ticker == \"CSE\":     ticker = \"CSE1\"\n",
				"        if ticker == \"AIT\":     ticker = \"AIT1\"\n",
				"        if ticker == \"PHB\":     ticker = \"PHB1\"\n",
				"        if ticker == \"FTL.A\":   ticker = \"FTL-A\" \n",
				"        if ticker == \"FRO\":     ticker = \"FRO1\"\n",
				"        if ticker == \"NLC\":     ticker = \"NLC1\"\n",
				"        if ticker == \"TA\":      ticker = \"TA2\"\n",
				"        if ticker == \"PVT\":     ticker = \"PVT1\"\n",
				"    #1100-1200\n",
				"    if 1100<=i<1200: \n",
				"        if ticker == \"ATI\":     ticker = \"ATI1\"\n",
				"        if ticker == \"ASND\":    ticker = \"ASND1\"\n",
				"        if ticker == \"ASC\":     ticker = \"ASC1\"\n",
				"        if ticker == \"HPH\":     ticker = \"HRZIQ\"\n",
				"        if ticker == \"FMY\":     ticker = \"FMY1\"\n",
				"        if ticker == \"UCC\":     ticker = \"UCC1\"\n",
				"        if ticker == \"ANV\":     ticker = \"ANV1\"\n",
				"        if ticker == \"AMP\":     ticker = \"AMP1\"\n",
				"        if ticker == \"PZE\":     ticker = \"PZE1\"\n",
				"        if ticker == \"CCI\":     ticker = \"CCI1\"\n",
				"        if ticker == \"GSX\":     ticker = \"GSX1\"\n",
				"        if ticker == \"FCN\":     ticker = \"FCN1\"\n",
				"        if ticker == \"AHM\":     ticker = \"AHM1\"\n",
				"        if ticker == \"DI\":      ticker = \"DI1\"\n",
				"        if ticker == \"MNR\":     ticker = \"MNR1\"\n",
				"        if ticker == \"BAY\":     ticker = \"BAY1\"\n",
				"        if ticker == \"DIGI\":    ticker = \"DIGI2\"\n",
				"        if ticker == \"GFS.A\":   ticker = \"GFS-A\"\n",
				"        if ticker == \"ECH\":     ticker = \"ECH1\"\n",
				"        if ticker == \"CHRS\":    ticker = \"CHRS1\"\n",
				"        if ticker == \"SK\":      ticker = \"SK1\"\n",
				"        if ticker == \"FLM\":     ticker = \"FLMIQ\"\n",
				"        \n",
				"    return ticker"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"#### Main\n",
				"    #NOTE: must make a new S3 client inside for each spark call; \n",
				"      #a single S3 client is not \"distributable\" and will run into \"lock/threads\" issues since a client is intended for \"one process\"\n",
				"\n",
				"Spark Times: (default - 3 workers)\n",
				"    43 seconds for all company_profiles (18 seconds for 10 workers)\n",
				"    29 minutes for all market_cap_data (2 minutes for 10 workers)\n",
				"    \n",
				"    127 seconds for everything(127 seconds for 10 workers)\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"     Ticker                   Name  ...     Removal_Reason Index\n",
						"0      DELL      Dell Technologies  ...               None     0\n",
						"1      ERIE         Erie Indemnity  ...               None     1\n",
						"2      PLTR  Palantir Technologies  ...               None     2\n",
						"3        SW       Smurfit WestRock  ...               None     3\n",
						"4      CRWD            CrowdStrike  ...               None     4\n",
						"...     ...                    ...  ...                ...   ...\n",
						"1148    ITT        ITT Corporation  ...  Annual Re-ranking  1148\n",
						"1149    PAS     Pepsiamericas Inc.  ...  Annual Re-ranking  1149\n",
						"1150    CBB     Caliber System Inc  ...  Annual Re-ranking  1150\n",
						"1151    ECO     Echo Bay Mines Ltd  ...  Annual Re-ranking  1151\n",
						"1152    BBI     Barnett Banks Inc.  ...  Annual Re-ranking  1152\n",
						"\n",
						"[1153 rows x 7 columns]\n"
					]
				}
			],
			"source": [
				"# Create an S3 client\n",
				"s3 = boto3.client('s3')\n",
				"# Define the bucket name and the file key (path to your CSV file in the bucket)\n",
				"bucket_name = 'sp500-historical-analysis-project'\n",
				"file_key = 'cleaned_sp_500_dataset.csv'\n",
				"response = s3.get_object(Bucket=bucket_name, Key=file_key) # Get the object from S3\n",
				"csv_content = response['Body'].read().decode('utf-8') # Read the file content as a string\n",
				"csv_buffer = StringIO(csv_content) # Use StringIO to convert the string data into a file-like object\n",
				"\n",
				"df = pd.read_csv(csv_buffer).iloc[:1153]\n",
				"df[\"Index\"] = [i for i in range(len(df))]\n",
				"df = df.where(pd.notnull(df), None) #replace \"NAN\" values with NULL\n",
				"print(df) # Display the DataFrame"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 19,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"meta_data_list = None\n",
				"bucket_name, file_key = 'sp500-historical-analysis-project', 'misc/tiingo_meta_data.json'\n",
				"response = s3.get_object(Bucket=bucket_name, Key=file_key) # Get the object from S3\n",
				"file_content = response['Body'].read().decode('utf-8') # Read the file content and load it as JSON\n",
				"meta_data_list = json.loads(file_content)\n",
				"\n",
				"def get_SP500_data(ticker, company_name, index, added_date, removal_date):\n",
				"    #NOTE: must make a new S3 client inside for each spark call; \n",
				"      #a single S3 client is not \"distributable\" and will run into \"lock/threads\" issues since a client is intended for \"one process\"\n",
				"    s3 = boto3.client('s3')\n",
				"\n",
				"    original_ticker = ticker\n",
				"\n",
				"    company_profile = {}\n",
				"    company_profile[\"ticker\"] = ticker\n",
				"\n",
				"    ticker = get_tiingo_ticker(ticker, index)\n",
				"    \n",
				"    a = get_company_data(ticker, company_profile, company_name, meta_data_list, original_ticker, index, s3)\n",
				"    b = get_market_cap_data(ticker, original_ticker, index, added_date, removal_date, company_name, s3)\n",
				"    return b"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 20,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"+------+--------------------+------------------+------------+--------+--------------+-----+\n",
						"|Ticker|                Name|        Added_Date|Removed_Date|Replaces|Removal_Reason|Index|\n",
						"+------+--------------------+------------------+------------+--------+--------------+-----+\n",
						"|  DELL|   Dell Technologies|September 23, 2024|        null|    ETSY|          null|    0|\n",
						"|  ERIE|      Erie Indemnity|September 23, 2024|        null|     BIO|          null|    1|\n",
						"|  PLTR|Palantir Technolo...|September 23, 2024|        null|     AAL|          null|    2|\n",
						"|    SW|    Smurfit WestRock|     July 05, 2024|        null|     WRK|          null|    3|\n",
						"|  CRWD|         CrowdStrike|     June 24, 2024|        null|    null|          null|    4|\n",
						"+------+--------------------+------------------+------------+--------+--------------+-----+\n",
						"only showing top 5 rows\n",
						"\n",
						"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
						"/opt/amazon/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n"
					]
				}
			],
			"source": [
				"spark_df = spark.createDataFrame(df)\n",
				"spark_df.show(5)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 23,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"[[{'date': '2024-09-23', 'market_cap': 83392886916.81}, {'date': '2024-09-24', 'market_cap': 83208467842.23}, {'date': '2024-09-25', 'market_cap': 85237077662.61}, {'date': '2024-09-26', 'market_cap': 89719879783.17}, {'date': '2024-09-27', 'market_cap': 85272542869.26}, {'date': '2024-09-30', 'market_cap': 84080911925.82}], [{'date': '2024-09-23', 'market_cap': 24864019830.8}, {'date': '2024-09-24', 'market_cap': 25167036792.4}, {'date': '2024-09-25', 'market_cap': 24894968209.5}, {'date': '2024-09-26', 'market_cap': 24845543186.8}, {'date': '2024-09-27', 'market_cap': 24897277790.0}, {'date': '2024-09-30', 'market_cap': 24935154910.2}], [{'date': '2024-09-23', 'market_cap': 84510719860.05}, {'date': '2024-09-24', 'market_cap': 82172478599.1}, {'date': '2024-09-25', 'market_cap': 82662395815.68}, {'date': '2024-09-26', 'market_cap': 82617857886.9}, {'date': '2024-09-27', 'market_cap': 82038864812.76}, {'date': '2024-09-30', 'market_cap': 83307680764.8}], [{'date': '2024-07-08', 'market_cap': 23877252000.0}, {'date': '2024-07-09', 'market_cap': 23159178000.0}, {'date': '2024-07-10', 'market_cap': 23675778000.0}, {'date': '2024-07-11', 'market_cap': 24213042000.0}, {'date': '2024-07-12', 'market_cap': 25354728000.0}, {'date': '2024-07-15', 'market_cap': 25230744000.0}, {'date': '2024-07-16', 'market_cap': 25447716000.0}, {'date': '2024-07-17', 'market_cap': 24719310000.0}, {'date': '2024-07-18', 'market_cap': 24187212000.0}, {'date': '2024-07-19', 'market_cap': 24037398000.0}, {'date': '2024-07-22', 'market_cap': 24796800000.0}, {'date': '2024-07-23', 'market_cap': 25370226000.0}, {'date': '2024-07-24', 'market_cap': 25241076000.0}, {'date': '2024-07-25', 'market_cap': 24636654000.0}, {'date': '2024-07-26', 'market_cap': 25215246000.0}, {'date': '2024-07-29', 'market_cap': 24564330000.0}, {'date': '2024-07-30', 'market_cap': 24145884000.0}, {'date': '2024-07-31', 'market_cap': 23164344000.0}, {'date': '2024-08-01', 'market_cap': 22379112000.0}, {'date': '2024-08-02', 'market_cap': 21583548000.0}, {'date': '2024-08-05', 'market_cap': 20684664000.0}, {'date': '2024-08-06', 'market_cap': 20834478000.0}, {'date': '2024-08-07', 'market_cap': 20178396000.0}, {'date': '2024-08-08', 'market_cap': 20307546000.0}, {'date': '2024-08-09', 'market_cap': 20126736000.0}, {'date': '2024-08-12', 'market_cap': 20069910000.0}, {'date': '2024-08-13', 'market_cap': 20844810000.0}, {'date': '2024-08-14', 'market_cap': 21289086000.0}, {'date': '2024-08-15', 'market_cap': 22079484000.0}, {'date': '2024-08-16', 'market_cap': 22167306000.0}, {'date': '2024-08-19', 'market_cap': 22466934000.0}, {'date': '2024-08-20', 'market_cap': 22218966000.0}, {'date': '2024-08-21', 'market_cap': 22740732000.0}, {'date': '2024-08-22', 'market_cap': 22621914000.0}, {'date': '2024-08-23', 'market_cap': 23417478000.0}, {'date': '2024-08-26', 'market_cap': 23856588000.0}, {'date': '2024-08-27', 'market_cap': 24223374000.0}, {'date': '2024-08-28', 'market_cap': 24316362000.0}, {'date': '2024-08-29', 'market_cap': 24368022000.0}, {'date': '2024-08-30', 'market_cap': 24497172000.0}, {'date': '2024-09-03', 'market_cap': 23608620000.0}, {'date': '2024-09-04', 'market_cap': 23541462000.0}, {'date': '2024-09-05', 'market_cap': 23422644000.0}, {'date': '2024-09-06', 'market_cap': 23102352000.0}, {'date': '2024-09-09', 'market_cap': 22973202000.0}, {'date': '2024-09-10', 'market_cap': 22379112000.0}, {'date': '2024-09-11', 'market_cap': 22487598000.0}, {'date': '2024-09-12', 'market_cap': 23035194000.0}, {'date': '2024-09-13', 'market_cap': 23205672000.0}, {'date': '2024-09-16', 'market_cap': 24140718000.0}, {'date': '2024-09-17', 'market_cap': 24450678000.0}, {'date': '2024-09-18', 'market_cap': 24724476000.0}, {'date': '2024-09-19', 'market_cap': 25323732000.0}, {'date': '2024-09-20', 'market_cap': 24492006000.0}, {'date': '2024-09-23', 'market_cap': 24145884000.0}, {'date': '2024-09-24', 'market_cap': 24538500000.0}, {'date': '2024-09-25', 'market_cap': 24693480000.0}, {'date': '2024-09-26', 'market_cap': 25576866000.0}, {'date': '2024-09-27', 'market_cap': 25876494000.0}, {'date': '2024-09-30', 'market_cap': 25666688322.66}], [{'date': '2024-06-24', 'market_cap': 91409421917.94}, {'date': '2024-06-25', 'market_cap': 93545122168.08}, {'date': '2024-06-26', 'market_cap': 91999581443.46}, {'date': '2024-06-27', 'market_cap': 93673312556.82}, {'date': '2024-06-28', 'market_cap': 92681651059.02}, {'date': '2024-07-01', 'market_cap': 94848794234.7}, {'date': '2024-07-02', 'market_cap': 93131526762.9}, {'date': '2024-07-03', 'market_cap': 93646707004.44}, {'date': '2024-07-05', 'market_cap': 94251378649.44}, {'date': '2024-07-08', 'market_cap': 94500503367.18}, {'date': '2024-07-09', 'market_cap': 93332277749.04}, {'date': '2024-07-10', 'market_cap': 90567718988.1}, {'date': '2024-07-11', 'market_cap': 89595406982.94}, {'date': '2024-07-12', 'market_cap': 89810670088.56}, {'date': '2024-07-15', 'market_cap': 91273975469.46}, {'date': '2024-07-16', 'market_cap': 89261628234.9}, {'date': '2024-07-17', 'market_cap': 85848861470.52}, {'date': '2024-07-18', 'market_cap': 82973043126.9}, {'date': '2024-07-19', 'market_cap': 73760265943.68}, {'date': '2024-07-22', 'market_cap': 63831557532.78}, {'date': '2024-07-23', 'market_cap': 65033644763.04}, {'date': '2024-07-24', 'market_cap': 62435975376.12}, {'date': '2024-07-25', 'market_cap': 61470919430.7}, {'date': '2024-07-26', 'market_cap': 61957075433.28}, {'date': '2024-07-29', 'market_cap': 62598027376.98}, {'date': '2024-07-30', 'market_cap': 56512611941.7}, {'date': '2024-07-31', 'market_cap': 56449933822.44}, {'date': '2024-08-01', 'market_cap': 54566322476.58}, {'date': '2024-08-02', 'market_cap': 53025849631.71}, {'date': '2024-08-05', 'market_cap': 54038229889.95}, {'date': '2024-08-06', 'market_cap': 56384226449.91}, {'date': '2024-08-07', 'market_cap': 56135998598.13}, {'date': '2024-08-08', 'market_cap': 58533100892.28}, {'date': '2024-08-09', 'market_cap': 58625577935.1}, {'date': '2024-08-12', 'market_cap': 58245935338.26}, {'date': '2024-08-13', 'market_cap': 60380208142.29}, {'date': '2024-08-14', 'market_cap': 62353862924.58}, {'date': '2024-08-15', 'market_cap': 63393012853.11}, {'date': '2024-08-16', 'market_cap': 63891902163.06}, {'date': '2024-08-19', 'market_cap': 64923751272.42}, {'date': '2024-08-20', 'market_cap': 64862911112.67}, {'date': '2024-08-21', 'market_cap': 66488560181.19}, {'date': '2024-08-22', 'market_cap': 65133041421.96}, {'date': '2024-08-23', 'market_cap': 66082147914.06}, {'date': '2024-08-26', 'market_cap': 64702293090.93}, {'date': '2024-08-27', 'market_cap': 65666001221.37}, {'date': '2024-08-28', 'market_cap': 64295880823.8}, {'date': '2024-08-29', 'market_cap': 66113784797.13}, {'date': '2024-08-30', 'market_cap': 67479037981.92}, {'date': '2024-09-03', 'market_cap': 64879946357.4}, {'date': '2024-09-04', 'market_cap': 63108280905.48}, {'date': '2024-09-05', 'market_cap': 62404968658.77}, {'date': '2024-09-06', 'market_cap': 59961627843.21}, {'date': '2024-09-09', 'market_cap': 60007866364.62}, {'date': '2024-09-10', 'market_cap': 60290164705.86}, {'date': '2024-09-11', 'market_cap': 61699222805.67}, {'date': '2024-09-12', 'market_cap': 62568020286.9}, {'date': '2024-09-13', 'market_cap': 63062042384.07}, {'date': '2024-09-16', 'market_cap': 65174412730.59}, {'date': '2024-09-17', 'market_cap': 65395870912.08}, {'date': '2024-09-18', 'market_cap': 65006493889.68}, {'date': '2024-09-19', 'market_cap': 67503374045.82}, {'date': '2024-09-20', 'market_cap': 72971687604.15}, {'date': '2024-09-23', 'market_cap': 71338737716.46}, {'date': '2024-09-24', 'market_cap': 70219278777.06}, {'date': '2024-09-25', 'market_cap': 69715522254.33}, {'date': '2024-09-26', 'market_cap': 68501152665.72}, {'date': '2024-09-27', 'market_cap': 69567072264.54}, {'date': '2024-09-30', 'market_cap': 68255358420.33}]]\n"
					]
				}
			],
			"source": [
				"result = spark_df.rdd.map(lambda x: get_SP500_data(x[\"Ticker\"], x[\"Name\"], x[\"Index\"], x[\"Added_Date\"], x[\"Removed_Date\"])).collect()\n",
				"result[:5]"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 24,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"1153\n"
					]
				}
			],
			"source": [
				"len(result)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 28,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"0: 6\n",
						"1: 6\n",
						"2: 6\n",
						"3: 60\n",
						"4: 69\n",
						"5: 69\n",
						"6: 69\n",
						"7: 100\n",
						"8: 127\n",
						"9: 127\n",
						"10: 137\n",
						"11: 137\n",
						"12: 198\n",
						"13: 198\n",
						"14: 198\n",
						"15: 240\n",
						"16: 240\n",
						"17: 249\n",
						"18: 262\n",
						"19: 262\n",
						"20: 277\n",
						"21: 323\n",
						"22: 355\n",
						"23: 387\n",
						"24: 390\n",
						"25: 390\n",
						"26: 437\n",
						"27: 445\n",
						"28: 446\n",
						"29: 481\n",
						"30: 495\n",
						"31: 502\n",
						"32: 502\n",
						"33: 512\n",
						"34: 512\n",
						"35: 574\n",
						"36: 574\n",
						"37: 582\n",
						"38: 3671\n",
						"39: 627\n",
						"40: 650\n",
						"41: 660\n",
						"42: 668\n",
						"43: 699\n",
						"44: 703\n",
						"45: 763\n",
						"46: 763\n",
						"47: 763\n",
						"48: 777\n",
						"49: 805\n",
						"50: 851\n",
						"51: 869\n",
						"52: 889\n",
						"53: 889\n",
						"54: 889\n",
						"55: 914\n",
						"56: 930\n",
						"57: 939\n",
						"58: 950\n",
						"59: 1002\n",
						"60: 1014\n",
						"61: 1014\n",
						"62: 1077\n",
						"63: 1077\n",
						"64: 1097\n",
						"65: 1105\n",
						"66: 1105\n",
						"67: 1131\n",
						"68: 1131\n",
						"69: 1154\n",
						"70: 1178\n",
						"71: 1201\n",
						"72: 1201\n",
						"73: 1201\n",
						"74: 1211\n",
						"75: 1213\n",
						"76: 1222\n",
						"77: 1257\n",
						"78: 1262\n",
						"79: 1265\n",
						"80: 1295\n",
						"81: 1295\n",
						"82: 6282\n",
						"83: 1314\n",
						"84: 1323\n",
						"85: 1336\n",
						"86: 1343\n",
						"87: 1342\n",
						"88: 1385\n",
						"89: 2274\n",
						"90: 4980\n",
						"91: 1409\n",
						"92: 1416\n",
						"93: 1435\n",
						"94: 1452\n",
						"95: 1466\n",
						"96: 1466\n",
						"97: 1479\n",
						"98: 1484\n",
						"99: 1502\n",
						"100: 1510\n",
						"101: 1533\n",
						"102: 1573\n",
						"103: 1581\n",
						"104: 1583\n",
						"105: 1592\n",
						"106: 1635\n",
						"107: 1645\n",
						"108: 1697\n",
						"109: 1752\n",
						"110: 1770\n",
						"111: 1781\n",
						"112: 1784\n",
						"113: 1808\n",
						"114: 1808\n",
						"115: 1808\n",
						"116: 1808\n",
						"117: 6729\n",
						"118: 1833\n",
						"119: 1833\n",
						"120: 1833\n",
						"121: 1833\n",
						"122: 1885\n",
						"123: 1896\n",
						"124: 1896\n",
						"125: 1896\n",
						"126: 6606\n",
						"127: 1899\n",
						"128: 1909\n",
						"129: 1910\n",
						"130: 1911\n",
						"131: 1947\n",
						"132: 1969\n",
						"133: 6729\n",
						"134: 1990\n",
						"135: 2018\n",
						"136: 2029\n",
						"137: 2030\n",
						"138: 2076\n",
						"139: 2075\n",
						"140: 2076\n",
						"141: 2096\n",
						"142: 2099\n",
						"143: 2104\n",
						"144: 2107\n",
						"145: 2124\n",
						"146: 2129\n",
						"147: 2142\n",
						"148: 2142\n",
						"149: 2158\n",
						"150: 2159\n",
						"151: 2182\n",
						"152: 2182\n",
						"153: 2191\n",
						"154: 2199\n",
						"155: 2204\n",
						"156: 2231\n",
						"157: 2242\n",
						"158: 2260\n",
						"159: 2273\n",
						"160: 2284\n",
						"161: 2316\n",
						"162: 3018\n",
						"163: 2329\n",
						"164: 2342\n",
						"165: 2389\n",
						"166: 2399\n",
						"167: 2402\n",
						"168: 2406\n",
						"169: 2437\n",
						"170: 2471\n",
						"171: 2524\n",
						"172: 2524\n",
						"173: 2580\n",
						"174: 2618\n",
						"175: 4656\n",
						"176: 2643\n",
						"177: 2690\n",
						"178: 2711\n",
						"179: 2711\n",
						"180: 2726\n",
						"181: 2775\n",
						"182: 2775\n",
						"183: 2783\n",
						"184: 2833\n",
						"185: 2838\n",
						"186: 2849\n",
						"187: 2875\n",
						"188: 2956\n",
						"189: 2962\n",
						"190: 2970\n",
						"191: 6729\n",
						"192: 2977\n",
						"193: 4406\n",
						"194: 3019\n",
						"195: 3037\n",
						"196: 3082\n",
						"197: 3100\n",
						"198: 3083\n",
						"199: 3107\n",
						"200: 3125\n",
						"201: 3158\n",
						"202: 3216\n",
						"203: 3216\n",
						"204: 3249\n",
						"205: 3260\n",
						"206: 3275\n",
						"207: 3332\n",
						"208: 6729\n",
						"209: 3334\n",
						"210: 3379\n",
						"211: 3396\n",
						"212: 3397\n",
						"213: 3468\n",
						"214: 3468\n",
						"215: 3490\n",
						"216: 3547\n",
						"217: 3578\n",
						"218: 3589\n",
						"219: 3663\n",
						"220: 3682\n",
						"221: 3694\n",
						"222: 3717\n",
						"223: 3719\n",
						"224: 3719\n",
						"225: 3751\n",
						"226: 3805\n",
						"227: 3913\n",
						"228: 3839\n",
						"229: 3839\n",
						"230: 3905\n",
						"231: 3922\n",
						"232: 3922\n",
						"233: 3944\n",
						"234: 3961\n",
						"235: 3981\n",
						"236: 3995\n",
						"237: 4001\n",
						"238: 4005\n",
						"239: 4012\n",
						"240: 4028\n",
						"241: 4034\n",
						"242: 4039\n",
						"243: 4039\n",
						"244: 4051\n",
						"245: 4055\n",
						"246: 4070\n",
						"247: 4079\n",
						"248: 4097\n",
						"249: 4111\n",
						"250: 4155\n",
						"251: 4156\n",
						"252: 4245\n",
						"253: 4261\n",
						"254: 4273\n",
						"255: 4279\n",
						"256: 4283\n",
						"257: 4295\n",
						"258: 4336\n",
						"259: 4343\n",
						"260: 4401\n",
						"261: 4415\n",
						"262: 4427\n",
						"263: 4446\n",
						"264: 4462\n",
						"265: 4496\n",
						"266: 4501\n",
						"267: 4501\n",
						"268: 4565\n",
						"269: 4614\n",
						"270: 4653\n",
						"271: 4656\n",
						"272: 2641\n",
						"273: 4698\n",
						"274: 4716\n",
						"275: 4746\n",
						"276: 4780\n",
						"277: 4781\n",
						"278: 4811\n",
						"279: 4817\n",
						"280: 4844\n",
						"281: 4844\n",
						"282: 5013\n",
						"283: 5055\n",
						"284: 6729\n",
						"285: 5098\n",
						"286: 5145\n",
						"287: 5184\n",
						"288: 5255\n",
						"289: 5346\n",
						"290: 5414\n",
						"291: 5420\n",
						"292: 6729\n",
						"293: 5141\n",
						"294: 5487\n",
						"295: 5503\n",
						"296: 6729\n",
						"297: 5585\n",
						"298: 5588\n",
						"299: 5588\n",
						"300: 5588\n",
						"301: 5588\n",
						"302: 5588\n",
						"303: 5588\n",
						"304: 5605\n",
						"305: 5726\n",
						"306: 5746\n",
						"307: 5747\n",
						"308: 6729\n",
						"309: 5807\n",
						"310: 5824\n",
						"311: 5912\n",
						"312: 5926\n",
						"313: 5934\n",
						"314: 5987\n",
						"315: 5988\n",
						"316: 5988\n",
						"317: 6014\n",
						"318: 6014\n",
						"319: 6059\n",
						"320: 6117\n",
						"321: 6120\n",
						"322: 6177\n",
						"323: 6478\n",
						"324: 6283\n",
						"325: 6289\n",
						"326: 6340\n",
						"327: 6354\n",
						"328: 6355\n",
						"329: 6358\n",
						"330: 6377\n",
						"331: 6471\n",
						"332: 6485\n",
						"333: 6508\n",
						"334: 6541\n",
						"335: 6542\n",
						"336: 6595\n",
						"337: 6565\n",
						"338: 6606\n",
						"339: 6036\n",
						"340: 6729\n",
						"341: 6650\n",
						"342: 6711\n",
						"343: 6729\n",
						"344: 6729\n",
						"345: 6729\n",
						"346: 6729\n",
						"347: 6729\n",
						"348: 6729\n",
						"349: 6729\n",
						"350: 6729\n",
						"351: 6729\n",
						"352: 6729\n",
						"353: 6729\n",
						"354: 6729\n",
						"355: 6729\n",
						"356: 6729\n",
						"357: 6729\n",
						"358: 6729\n",
						"359: 6729\n",
						"360: 6729\n",
						"361: 6729\n",
						"362: 6729\n",
						"363: 6729\n",
						"364: 6729\n",
						"365: 6729\n",
						"366: 6729\n",
						"367: 6729\n",
						"368: 6729\n",
						"369: 6729\n",
						"370: 6729\n",
						"371: 6729\n",
						"372: 6729\n",
						"373: 6729\n",
						"374: 6729\n",
						"375: 6729\n",
						"376: 6729\n",
						"377: 6729\n",
						"378: 6729\n",
						"379: 6729\n",
						"380: 6729\n",
						"381: 6729\n",
						"382: 6729\n",
						"383: 6729\n",
						"384: 6729\n",
						"385: 6729\n",
						"386: 6729\n",
						"387: 6729\n",
						"388: 6729\n",
						"389: 6729\n",
						"390: 6729\n",
						"391: 6729\n",
						"392: 6729\n",
						"393: 6729\n",
						"394: 6729\n",
						"395: 6729\n",
						"396: 6729\n",
						"397: 6729\n",
						"398: 6729\n",
						"399: 6729\n",
						"400: 6729\n",
						"401: 6729\n",
						"402: 6729\n",
						"403: 6729\n",
						"404: 6729\n",
						"405: 6729\n",
						"406: 6729\n",
						"407: 6729\n",
						"408: 6729\n",
						"409: 6729\n",
						"410: 6729\n",
						"411: 6729\n",
						"412: 6729\n",
						"413: 6729\n",
						"414: 6729\n",
						"415: 6729\n",
						"416: 6729\n",
						"417: 6729\n",
						"418: 6729\n",
						"419: 6729\n",
						"420: 6729\n",
						"421: 6729\n",
						"422: 6729\n",
						"423: 6729\n",
						"424: 6729\n",
						"425: 6729\n",
						"426: 6729\n",
						"427: 6729\n",
						"428: 6729\n",
						"429: 6729\n",
						"430: 6729\n",
						"431: 6729\n",
						"432: 6729\n",
						"433: 6729\n",
						"434: 6729\n",
						"435: 6729\n",
						"436: 6729\n",
						"437: 6729\n",
						"438: 6729\n",
						"439: 6729\n",
						"440: 6729\n",
						"441: 6729\n",
						"442: 6729\n",
						"443: 6729\n",
						"444: 6729\n",
						"445: 6729\n",
						"446: 6729\n",
						"447: 6729\n",
						"448: 6729\n",
						"449: 6729\n",
						"450: 6729\n",
						"451: 6729\n",
						"452: 6729\n",
						"453: 6729\n",
						"454: 6729\n",
						"455: 6729\n",
						"456: 6396\n",
						"457: 6729\n",
						"458: 6729\n",
						"459: 6729\n",
						"460: 6729\n",
						"461: 6729\n",
						"462: 6729\n",
						"463: 6729\n",
						"464: 6729\n",
						"465: 6729\n",
						"466: 6729\n",
						"467: 6729\n",
						"468: 6729\n",
						"469: 6729\n",
						"470: 6729\n",
						"471: 6729\n",
						"472: 6729\n",
						"473: 6729\n",
						"474: 6729\n",
						"475: 6729\n",
						"476: 6729\n",
						"477: 6729\n",
						"478: 6729\n",
						"479: 6729\n",
						"480: 6729\n",
						"481: 6729\n",
						"482: 6729\n",
						"483: 6729\n",
						"484: 6729\n",
						"485: 6729\n",
						"486: 6729\n",
						"487: 6729\n",
						"488: 6729\n",
						"489: 6729\n",
						"490: 6729\n",
						"491: 6729\n",
						"492: 6729\n",
						"493: 6729\n",
						"494: 6729\n",
						"495: 6729\n",
						"496: 6729\n",
						"497: 6729\n",
						"498: 6729\n",
						"499: 6729\n",
						"500: 6729\n",
						"501: 6729\n",
						"502: 6729\n",
						"503: 1009\n",
						"504: 1072\n",
						"505: 2394\n",
						"506: 2268\n",
						"507: 5923\n",
						"508: 6661\n",
						"509: 2162\n",
						"510: 3930\n",
						"511: 6604\n",
						"512: 3870\n",
						"513: 6593\n",
						"514: 5718\n",
						"515: 502\n",
						"516: 1913\n",
						"517: 6472\n",
						"518: 599\n",
						"519: 2046\n",
						"520: 1636\n",
						"521: 6468\n",
						"522: 6468\n",
						"523: 2048\n",
						"524: 1579\n",
						"525: 1090\n",
						"526: 6036\n",
						"527: 1256\n",
						"528: 308\n",
						"529: 4380\n",
						"530: 1151\n",
						"531: 3\n",
						"532: 1636\n",
						"533: 1109\n",
						"534: 2334\n",
						"535: 5747\n",
						"536: 1307\n",
						"537: 378\n",
						"538: 2416\n",
						"539: 1081\n",
						"540: 1557\n",
						"541: 2050\n",
						"542: 3049\n",
						"543: 1935\n",
						"544: 3370\n",
						"545: 1194\n",
						"546: 5605\n",
						"547: 6062\n",
						"548: 3831\n",
						"549: 1701\n",
						"550: 5581\n",
						"551: 2156\n",
						"552: 4160\n",
						"553: 2454\n",
						"554: 5967\n",
						"555: 690\n",
						"556: 2303\n",
						"557: 747\n",
						"558: 3113\n",
						"559: 3571\n",
						"560: 5841\n",
						"561: 3138\n",
						"562: 1511\n",
						"563: 111\n",
						"564: 2944\n",
						"565: 1237\n",
						"566: 5170\n",
						"567: 4476\n",
						"568: 3274\n",
						"569: 4157\n",
						"570: 5562\n",
						"571: 999\n",
						"572: 5716\n",
						"573: 5653\n",
						"574: 5131\n",
						"575: 1635\n",
						"576: 2577\n",
						"577: 5306\n",
						"578: 1634\n",
						"579: 5601\n",
						"580: 5600\n",
						"581: 1434\n",
						"582: 341\n",
						"583: 1381\n",
						"584: 2014\n",
						"585: 1669\n",
						"586: 5519\n",
						"587: 3505\n",
						"588: 3284\n",
						"589: 389\n",
						"590: 3043\n",
						"591: 2949\n",
						"592: 845\n",
						"593: 5435\n",
						"594: 2505\n",
						"595: 3670\n",
						"596: 5391\n",
						"597: 439\n",
						"598: 4637\n",
						"599: 415\n",
						"600: 5321\n",
						"601: 2053\n",
						"602: 5295\n",
						"603: 2517\n",
						"604: 3837\n",
						"605: 2527\n",
						"606: 5262\n",
						"607: 4380\n",
						"608: 2493\n",
						"609: 5246\n",
						"610: 468\n",
						"611: 2773\n",
						"612: 4286\n",
						"613: 1188\n",
						"614: 2452\n",
						"615: 4896\n",
						"616: 2640\n",
						"617: 536\n",
						"618: 3980\n",
						"619: 1031\n",
						"620: 2977\n",
						"621: 589\n",
						"622: 666\n",
						"623: 3131\n",
						"624: 3033\n",
						"625: 2438\n",
						"626: 5031\n",
						"627: 741\n",
						"628: 4769\n",
						"629: 0\n",
						"630: 4949\n",
						"631: 2935\n",
						"632: 3641\n",
						"633: 3008\n",
						"634: 942\n",
						"635: 4483\n",
						"636: 740\n",
						"637: 3750\n",
						"638: 4897\n",
						"639: 4411\n",
						"640: 2447\n",
						"641: 1887\n",
						"642: 4885\n",
						"643: 0\n",
						"644: 2222\n",
						"645: 1869\n",
						"646: 4038\n",
						"647: 1791\n",
						"648: 2797\n",
						"649: 4263\n",
						"650: 529\n",
						"651: 4820\n",
						"652: 2557\n",
						"653: 4783\n",
						"654: 1995\n",
						"655: 2674\n",
						"656: 4740\n",
						"657: 1915\n",
						"658: 3986\n",
						"659: 4701\n",
						"660: 4700\n",
						"661: 254\n",
						"662: 3708\n",
						"663: 4654\n",
						"664: 1385\n",
						"665: 232\n",
						"666: 4439\n",
						"667: 1688\n",
						"668: 1798\n",
						"669: 2535\n",
						"670: 902\n",
						"671: 2104\n",
						"672: 4601\n",
						"673: 2060\n",
						"674: 921\n",
						"675: 2110\n",
						"676: 493\n",
						"677: 2438\n",
						"678: 3548\n",
						"679: 3919\n",
						"680: 2183\n",
						"681: 4539\n",
						"682: 944\n",
						"683: 3948\n",
						"684: 60\n",
						"685: 3745\n",
						"686: 4500\n",
						"687: 2508\n",
						"688: 2195\n",
						"689: 1162\n",
						"690: 2855\n",
						"691: 4443\n",
						"692: 2175\n",
						"693: 1133\n",
						"694: 3502\n",
						"695: 4402\n",
						"696: 1259\n",
						"697: 2104\n",
						"698: 1764\n",
						"699: 2195\n",
						"700: 4013\n",
						"701: 1503\n",
						"702: 3627\n",
						"703: 4331\n",
						"704: 1395\n",
						"705: 610\n",
						"706: 984\n",
						"707: 4075\n",
						"708: 4259\n",
						"709: 3464\n",
						"710: 1694\n",
						"711: 1972\n",
						"712: 4183\n",
						"713: 4150\n",
						"714: 3420\n",
						"715: 3219\n",
						"716: 4112\n",
						"717: 3985\n",
						"718: 4107\n",
						"719: 1077\n",
						"720: 558\n",
						"721: 1300\n",
						"722: 3373\n",
						"723: 3549\n",
						"724: 1698\n",
						"725: 3522\n",
						"726: 4004\n",
						"727: 1525\n",
						"728: 3964\n",
						"729: 3955\n",
						"730: 945\n",
						"731: 3760\n",
						"732: 3902\n",
						"733: 2802\n",
						"734: 2804\n",
						"735: 3881\n",
						"736: 1799\n",
						"737: 1936\n",
						"738: 966\n",
						"739: 3793\n",
						"740: 2446\n",
						"741: 1299\n",
						"742: 3760\n",
						"743: 257\n",
						"744: 3715\n",
						"745: 338\n",
						"746: 837\n",
						"747: 3306\n",
						"748: 1877\n",
						"749: 3668\n",
						"750: 3648\n",
						"751: 3647\n",
						"752: 3011\n",
						"753: 3167\n",
						"754: 352\n",
						"755: 3605\n",
						"756: 2173\n",
						"757: 3239\n",
						"758: 3272\n",
						"759: 3516\n",
						"760: 876\n",
						"761: 2654\n",
						"762: 1150\n",
						"763: 2861\n",
						"764: 3481\n",
						"765: 735\n",
						"766: 3453\n",
						"767: 2368\n",
						"768: 3396\n",
						"769: 743\n",
						"770: 3351\n",
						"771: 2342\n",
						"772: 2700\n",
						"773: 550\n",
						"774: 2568\n",
						"775: 2539\n",
						"776: 3272\n",
						"777: 0\n",
						"778: 2892\n",
						"779: 3262\n",
						"780: 2569\n",
						"781: 2776\n",
						"782: 984\n",
						"783: 0\n",
						"784: 901\n",
						"785: 1375\n",
						"786: 2005\n",
						"787: 3067\n",
						"788: 3051\n",
						"789: 2208\n",
						"790: 3048\n",
						"791: 1473\n",
						"792: 3034\n",
						"793: 750\n",
						"794: 3011\n",
						"795: 2396\n",
						"796: 3011\n",
						"797: 2318\n",
						"798: 2089\n",
						"799: 2977\n",
						"800: 2964\n",
						"801: 2939\n",
						"802: 451\n",
						"803: 2925\n",
						"804: 1195\n",
						"805: 1798\n",
						"806: 786\n",
						"807: 502\n",
						"808: 487\n",
						"809: 2850\n",
						"810: 2829\n",
						"811: 509\n",
						"812: 2061\n",
						"813: 2817\n",
						"814: 1815\n",
						"815: 418\n",
						"816: 906\n",
						"817: 1155\n",
						"818: 2769\n",
						"819: 2767\n",
						"820: 2767\n",
						"821: 2767\n",
						"822: 713\n",
						"823: 2257\n",
						"824: 2353\n",
						"825: 2746\n",
						"826: 2741\n",
						"827: 2738\n",
						"828: 2735\n",
						"829: 2735\n",
						"830: 348\n",
						"831: 2732\n",
						"832: 474\n",
						"833: 2725\n",
						"834: 2718\n",
						"835: 2706\n",
						"836: 2702\n",
						"837: 0\n",
						"838: 2697\n",
						"839: 2688\n",
						"840: 2689\n",
						"841: 2689\n",
						"842: 2528\n",
						"843: 433\n",
						"844: 0\n",
						"845: 1629\n",
						"846: 636\n",
						"847: 2639\n",
						"848: 2633\n",
						"849: 2633\n",
						"850: 1884\n",
						"851: 1530\n",
						"852: 2494\n",
						"853: 2573\n",
						"854: 457\n",
						"855: 2532\n",
						"856: 2514\n",
						"857: 2513\n",
						"858: 0\n",
						"859: 2503\n",
						"860: 2485\n",
						"861: 2484\n",
						"862: 2294\n",
						"863: 2470\n",
						"864: 1777\n",
						"865: 0\n",
						"866: 2457\n",
						"867: 705\n",
						"868: 2201\n",
						"869: 1946\n",
						"870: 1856\n",
						"871: 2446\n",
						"872: 685\n",
						"873: 1763\n",
						"874: 2394\n",
						"875: 0\n",
						"876: 2387\n",
						"877: 1484\n",
						"878: 1766\n",
						"879: 1991\n",
						"880: 1748\n",
						"881: 1623\n",
						"882: 0\n",
						"883: 1770\n",
						"884: 1542\n",
						"885: 754\n",
						"886: 2315\n",
						"887: 1337\n",
						"888: 2297\n",
						"889: 1686\n",
						"890: 1344\n",
						"891: 1827\n",
						"892: 1527\n",
						"893: 2262\n",
						"894: 2263\n",
						"895: 2256\n",
						"896: 0\n",
						"897: 2241\n",
						"898: 1105\n",
						"899: 0\n",
						"900: 2234\n",
						"901: 576\n",
						"902: 2229\n",
						"903: 1929\n",
						"904: 2200\n",
						"905: 2200\n",
						"906: 2165\n",
						"907: 2080\n",
						"908: 2157\n",
						"909: 2147\n",
						"910: 2134\n",
						"911: 2118\n",
						"912: 2116\n",
						"913: 1350\n",
						"914: 2088\n",
						"915: 1356\n",
						"916: 2074\n",
						"917: 2074\n",
						"918: 2074\n",
						"919: 2074\n",
						"920: 0\n",
						"921: 2049\n",
						"922: 1443\n",
						"923: 2032\n",
						"924: 1386\n",
						"925: 2012\n",
						"926: 1385\n",
						"927: 2004\n",
						"928: 0\n",
						"929: 1984\n",
						"930: 1603\n",
						"931: 1949\n",
						"932: 1949\n",
						"933: 1926\n",
						"934: 0\n",
						"935: 1853\n",
						"936: 773\n",
						"937: 1913\n",
						"938: 1899\n",
						"939: 1886\n",
						"940: 1318\n",
						"941: 1817\n",
						"942: 1101\n",
						"943: 1569\n",
						"944: 1751\n",
						"945: 1751\n",
						"946: 1751\n",
						"947: 1379\n",
						"948: 1428\n",
						"949: 830\n",
						"950: 1056\n",
						"951: 1654\n",
						"952: 1444\n",
						"953: 1632\n",
						"954: 1591\n",
						"955: 711\n",
						"956: 781\n",
						"957: 0\n",
						"958: 1570\n",
						"959: 1565\n",
						"960: 729\n",
						"961: 953\n",
						"962: 970\n",
						"963: 1415\n",
						"964: 1326\n",
						"965: 1316\n",
						"966: 1310\n",
						"967: 1305\n",
						"968: 267\n",
						"969: 1243\n",
						"970: 1227\n",
						"971: 771\n",
						"972: 422\n",
						"973: 512\n",
						"974: 0\n",
						"975: 1142\n",
						"976: 0\n",
						"977: 1142\n",
						"978: 0\n",
						"979: 1142\n",
						"980: 1142\n",
						"981: 0\n",
						"982: 206\n",
						"983: 603\n",
						"984: 0\n",
						"985: 1096\n",
						"986: 505\n",
						"987: 1087\n",
						"988: 1031\n",
						"989: 722\n",
						"990: 1023\n",
						"991: 0\n",
						"992: 1004\n",
						"993: 994\n",
						"994: 992\n",
						"995: 984\n",
						"996: 983\n",
						"997: 967\n",
						"998: 510\n",
						"999: 947\n",
						"1000: 501\n",
						"1001: 925\n",
						"1002: 208\n",
						"1003: 923\n",
						"1004: 923\n",
						"1005: 906\n",
						"1006: 905\n",
						"1007: 904\n",
						"1008: 885\n",
						"1009: 881\n",
						"1010: 879\n",
						"1011: 876\n",
						"1012: 0\n",
						"1013: 408\n",
						"1014: 819\n",
						"1015: 13\n",
						"1016: 335\n",
						"1017: 780\n",
						"1018: 781\n",
						"1019: 775\n",
						"1020: 514\n",
						"1021: 751\n",
						"1022: 743\n",
						"1023: 743\n",
						"1024: 12\n",
						"1025: 567\n",
						"1026: 0\n",
						"1027: 740\n",
						"1028: 742\n",
						"1029: 742\n",
						"1030: 742\n",
						"1031: 0\n",
						"1032: 368\n",
						"1033: 731\n",
						"1034: 730\n",
						"1035: 0\n",
						"1036: 362\n",
						"1037: 716\n",
						"1038: 716\n",
						"1039: 708\n",
						"1040: 705\n",
						"1041: 683\n",
						"1042: 694\n",
						"1043: 188\n",
						"1044: 693\n",
						"1045: 671\n",
						"1046: 453\n",
						"1047: 648\n",
						"1048: 647\n",
						"1049: 639\n",
						"1050: 324\n",
						"1051: 0\n",
						"1052: 630\n",
						"1053: 0\n",
						"1054: 628\n",
						"1055: 0\n",
						"1056: 620\n",
						"1057: 620\n",
						"1058: 617\n",
						"1059: 619\n",
						"1060: 616\n",
						"1061: 613\n",
						"1062: 610\n",
						"1063: 608\n",
						"1064: 593\n",
						"1065: 590\n",
						"1066: 590\n",
						"1067: 578\n",
						"1068: 565\n",
						"1069: 567\n",
						"1070: 555\n",
						"1071: 523\n",
						"1072: 523\n",
						"1073: 523\n",
						"1074: 0\n",
						"1075: 504\n",
						"1076: 503\n",
						"1077: 0\n",
						"1078: 482\n",
						"1079: 482\n",
						"1080: 472\n",
						"1081: 471\n",
						"1082: 466\n",
						"1083: 465\n",
						"1084: 474\n",
						"1085: 457\n",
						"1086: 484\n",
						"1087: 448\n",
						"1088: 447\n",
						"1089: 441\n",
						"1090: 440\n",
						"1091: 440\n",
						"1092: 438\n",
						"1093: 398\n",
						"1094: 406\n",
						"1095: 402\n",
						"1096: 0\n",
						"1097: 397\n",
						"1098: 390\n",
						"1099: 0\n",
						"1100: 375\n",
						"1101: 262\n",
						"1102: 371\n",
						"1103: 369\n",
						"1104: 0\n",
						"1105: 357\n",
						"1106: 353\n",
						"1107: 224\n",
						"1108: 334\n",
						"1109: 319\n",
						"1110: 314\n",
						"1111: 308\n",
						"1112: 0\n",
						"1113: 290\n",
						"1114: 259\n",
						"1115: 252\n",
						"1116: 0\n",
						"1117: 252\n",
						"1118: 251\n",
						"1119: 245\n",
						"1120: 226\n",
						"1121: 222\n",
						"1122: 217\n",
						"1123: 193\n",
						"1124: 0\n",
						"1125: 189\n",
						"1126: 189\n",
						"1127: 188\n",
						"1128: 188\n",
						"1129: 185\n",
						"1130: 177\n",
						"1131: 166\n",
						"1132: 165\n",
						"1133: 155\n",
						"1134: 152\n",
						"1135: 135\n",
						"1136: 134\n",
						"1137: 130\n",
						"1138: 124\n",
						"1139: 124\n",
						"1140: 124\n",
						"1141: 123\n",
						"1142: 111\n",
						"1143: 80\n",
						"1144: 78\n",
						"1145: 66\n",
						"1146: 61\n",
						"1147: 61\n",
						"1148: 34\n",
						"1149: 19\n",
						"1150: 17\n",
						"1151: 0\n",
						"1152: 6\n"
					]
				}
			],
			"source": [
				"for i, x in enumerate(result):\n",
				"    print(str(i) + \": \" + str(len(x)))"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": []
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
